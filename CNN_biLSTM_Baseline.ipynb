{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN-biLSTM Baseline",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqqB9GxC5HjA",
        "colab_type": "text"
      },
      "source": [
        "### Step 1: Configure notebook\n",
        "\n",
        "This notebook might stall when trying to mount the google drive.  It will prompt for an authentication key.  I'm not sure how often it expires.\n",
        "\n",
        "\n",
        "### Step 2: Prepare embeddings\n",
        "\n",
        "There are 3 index types / embeddings:\n",
        "+ Words\n",
        "  + These are imported from Glove and minimal formatting is applied.\n",
        "+ Characters\n",
        "  + These are trained in the model.  However, the dictionary of acceptable values is determined at this stage from `string.printable`\n",
        "+ Casing\n",
        "  + A dictionary is initialized at this stage from hard-coded options.\n",
        "+ Labels\n",
        "  + The ontonotes training data is used as the source of possible labels.  In addition the 'TITLE' tags are also added to the labels dictionary.\n",
        "\n",
        "\n",
        "### Step 3: Process data\n",
        "\n",
        "There are three distinct varieties of data:\n",
        "+ Original Ontonotes data\n",
        "  + This data will be used for pre-training the model.  All 3 sets (train, dev, test) are used.\n",
        "  + The data originates in a 4-column CoNLL format.  We are only interested in the token and label columns.  Each line is a token.  Sentence divisions are indicated by an empty line.\n",
        "  + Train: for pre-training the model\n",
        "  + Dev: for determining when the model is trained\n",
        "  + Test: for establishing the generalized accuracy of the model\n",
        "+ Domain data\n",
        "  + This is the manually annotated data that we will use to fine-tune and test our model.\n",
        "  + It follows a similar format to Ontonotes (4-column, with column order preserved), however the middle two columns have been replaced with 'company' and 'director'\n",
        "+ BILOU formatted data\n",
        "  + There are versions of the ontonotes and domain data in this format.\n",
        "  + It is 2-column, (array_of_tokens, array_of_labels).  Each line is a sentence.\n",
        "\n",
        "The data needs to be formatted into 4 vectors per sample (word, char, casing, label), where each sample is a sentence.  Each of these vectors needs to be truncated / padded.\n",
        "\n",
        "There is a caching function that can be used to store the very large (~7GB) vectorized data files.\n",
        "\n",
        "### Step 4: Build / Train Model\n",
        "\n",
        "### Step 5: Fine-tune model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeMAhNAtb-3C",
        "colab_type": "text"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO-mWSKC5Fv_",
        "colab_type": "code",
        "outputId": "ba3f7b4b-fac0-422d-d671-449bb8342bf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import os\n",
        "import time\n",
        "import sys\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import ast\n",
        "from IPython.display import display\n",
        "\n",
        "from shutil import copyfile\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "csv.field_size_limit(sys.maxsize)\n",
        "\n",
        "from keras.layers import TimeDistributed, Conv1D, Dense, Embedding, Input, Dropout, LSTM, Bidirectional, MaxPooling1D, Flatten, concatenate\n",
        "from keras.initializers import RandomUniform\n",
        "from keras.optimizers import SGD, Nadam\n",
        "from keras.models import Model, load_model, Sequential\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.utils import plot_model\n",
        "\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "np.random.seed(1492)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nkq7QaJRW7Lr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### File configurations\n",
        "drive_dir = \"/content/drive/My Drive/W266_Project/\"\n",
        "data_src = os.path.join(drive_dir,\"data\")\n",
        "embed_src = os.path.join(drive_dir,\"embeddings\")\n",
        "\n",
        "# cache store\n",
        "cache_dir = os.path.join(drive_dir, \"cache\")\n",
        "embed_store =  os.path.join(cache_dir, 'embed.h5')\n",
        "\n",
        "### Model Parameters\n",
        "DROPOUT = 0.2\n",
        "RECURRENT_DROPOUT = 0.25\n",
        "CHAR_VOCAB = len(string.printable)\n",
        "CHAR_EMBEDDING_DIM = 30\n",
        "WORD_LENGTH = 52\n",
        "CONV_SIZE = 3\n",
        "CONV_FILTERS = 30\n",
        "CONV_STRIDE = 1\n",
        "CONV_WINDOW = 52\n",
        "LSTM_STATE_SIZE = 200\n",
        "\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 400\n",
        "TRAINING_SIZE = 600000\n",
        "\n",
        "# embedding to use\n",
        "# 50d vector is consistent with paper\n",
        "embedding_file = \"glove.6B.50d.txt\"\n",
        "\n",
        "annotation_type = \"BILOU\"\n",
        "\n",
        "# data files\n",
        "train_file = None\n",
        "dev_file = None\n",
        "test_file = None\n",
        "real_file = None\n",
        "\n",
        "if annotation_type == \"BIO\":\n",
        "  train_file = 'onto.train.ner'\n",
        "  dev_file = 'onto.development.ner'\n",
        "  test_file = 'onto.test.ner'\n",
        "  real_file = 'bios-tagged-final-flat.csv'\n",
        "elif annotation_type == \"BILOU\":\n",
        "  train_file = 'onto.train.ner_bilou.csv'\n",
        "  dev_file = 'onto.development.ner_bilou.csv'\n",
        "  test_file = 'onto.test.ner_bilou.csv'\n",
        "  real_file = 'bios-tagged-final-flat_bilou.csv'\n",
        "else:\n",
        "  raise Exception(f\"unknown annotation: {annotation_type}\")\n",
        "\n",
        "real_training_sizes = [10,25,50,100,200,300]\n",
        "# whether to freeze the weights on the bilstm\n",
        "FROZEN = False\n",
        "# which layer weights to copy over for fine_tuning\n",
        "# None results in all weights, otherwise provide an array of layer names\n",
        "FINE_TUNE_LAYERS = ['biLSTM', 'softmax']\n",
        "\n",
        "model_dir = os.path.join(drive_dir, 'output')\n",
        "\n",
        "# if loading a pre-trained model set these\n",
        "model_name = \"\"\n",
        "model_load_path = os.path.join(model_dir, model_name + '.h5')\n",
        "INITIAL_EPOCH = EPOCHS\n",
        "\n",
        "# else use these\n",
        "model_name = f\"std_400b_glove50d_baseline_{annotation_type}\"\n",
        "model_path = os.path.join(model_dir, model_name + '_{epoch:02d}-{val_loss:.4f}.h5')\n",
        "\n",
        "\n",
        "\n",
        "### Preprocessing Parameters\n",
        "UNK_WORD = \"<UNK-WORD>\"\n",
        "PAD_WORD = \"<PAD-WORD>\"\n",
        "\n",
        "UNK_CHAR = \"<UNK-CHAR>\"\n",
        "PAD_CHAR = \"<PAD-CHAR>\"\n",
        "\n",
        "# max number of words in a sentence, pad to this length, might throw an error if the sentence is longer\n",
        "SENTENCE_WIDTH = 256\n",
        "# max number of characters in a word, pad to this length, will truncate if word is too long\n",
        "WORD_WIDTH = 52\n",
        "# symbols to map padding to\n",
        "CHAR_PAD_SYMBOL = PAD_CHAR\n",
        "LABEL_PAD_SYMBOL = 'O'\n",
        "CASE_PAD_SYMBOL = 'other'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fexOHcCYV9jG",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwdmu-_rWhpu",
        "colab_type": "code",
        "outputId": "ffd6a353-33cf-471a-c33d-6142efbc3f88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# show files\n",
        "print(os.listdir(data_src))\n",
        "print(os.listdir(embed_src))\n",
        "print(os.listdir(cache_dir))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['onto.development.ner.sample', 'onto.development.ner', 'onto.test.ner.sample', 'onto.train.ner.sample', 'onto.test.ner', 'onto.train.ner', 'bios-tagged_bilou.csv', 'bios-tagged-set1.csv', 'bios-tagged-set2.csv', 'bios-tagged-final-flat.csv', 'bios-tagged-final-agg.csv', 'onto.train.ner_bilou.csv', 'onto.development.ner_bilou.csv', 'onto.test.ner_bilou.csv', 'bios-tagged-final-flat_bilou.csv']\n",
            "['glove.6B.100d.txt', 'glove.6B.200d.txt', 'glove.6B.300d.txt', 'glove.6B.50d.txt', 'readme.md', 'Skip100']\n",
            "['embed.h5', 'onto_train_ner_bilou_word.npy', 'onto_train_ner_bilou_label.npy', 'onto_train_ner_bilou_case.npy', 'onto_train_ner_bilou_char.npy', 'onto_development_ner_bilou_word.npy', 'onto_development_ner_bilou_case.npy', 'onto_development_ner_bilou_label.npy', 'onto_development_ner_bilou_char.npy', 'onto_test_ner_bilou_word.npy', 'onto_test_ner_bilou_case.npy', 'onto_test_ner_bilou_label.npy', 'onto_test_ner_bilou_char.npy', 'bios-tagged_bilou_word.npy', 'bios-tagged_bilou_char.npy', 'bios-tagged_bilou_case.npy', 'bios-tagged_bilou_label.npy', 'bios-tagged-final-flat_bilou_word.npy', 'bios-tagged-final-flat_bilou_char.npy', 'bios-tagged-final-flat_bilou_case.npy', 'bios-tagged-final-flat_bilou_label.npy', 'onto_train_ner_word.npy', 'onto_train_ner_case.npy', 'onto_train_ner_label.npy', 'onto_development_ner_word.npy', 'onto_development_ner_case.npy', 'onto_development_ner_label.npy', 'onto_development_ner_char.npy', 'onto_test_ner_word.npy', 'onto_test_ner_case.npy', 'onto_test_ner_label.npy', 'onto_train_ner_char.npy', 'onto_test_ner_char.npy', 'bios-tagged-final-flat_word.npy', 'bios-tagged-final-flat_char.npy', 'bios-tagged-final-flat_case.npy', 'bios-tagged-final-flat_label.npy', 'onto_train_ner_bilou_BILOU_word.npy', 'onto_train_ner_bilou_BILOU_char.npy', 'onto_train_ner_bilou_BILOU_case.npy', 'onto_train_ner_bilou_BILOU_label.npy', 'onto_development_ner_bilou_BILOU_word.npy', 'onto_development_ner_bilou_BILOU_char.npy', 'onto_development_ner_bilou_BILOU_case.npy', 'onto_development_ner_bilou_BILOU_label.npy', 'onto_test_ner_bilou_BILOU_word.npy', 'onto_test_ner_bilou_BILOU_char.npy', 'onto_test_ner_bilou_BILOU_case.npy', 'onto_test_ner_bilou_BILOU_label.npy', 'bios-tagged-final-flat_bilou_BILOU_word.npy', 'bios-tagged-final-flat_bilou_BILOU_char.npy', 'bios-tagged-final-flat_bilou_BILOU_case.npy', 'bios-tagged-final-flat_bilou_BILOU_label.npy', 'onto_train_ner_BIO_word.npy', 'onto_train_ner_BIO_label.npy', 'onto_train_ner_BIO_case.npy', 'onto_development_ner_BIO_word.npy', 'onto_development_ner_BIO_case.npy', 'onto_development_ner_BIO_label.npy', 'onto_development_ner_BIO_char.npy', 'onto_test_ner_BIO_word.npy', 'onto_test_ner_BIO_case.npy', 'onto_test_ner_BIO_label.npy', 'bios-tagged-final-flat_BIO_word.npy', 'bios-tagged-final-flat_BIO_char.npy', 'bios-tagged-final-flat_BIO_case.npy', 'bios-tagged-final-flat_BIO_label.npy', 'onto_test_ner_BIO_char.npy', 'onto_train_ner_BIO_char.npy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2r4lsXGrLkV",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCpi-_CPcdZ8",
        "colab_type": "text"
      },
      "source": [
        "## Load Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ5j2-luYnKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# consider using tf.nn.embedding_lookup instead\n",
        "# or maybe nltk.tokenize\n",
        "\n",
        "\n",
        "def get_casing_ix(word):\n",
        "  '''\n",
        "  determines the casing of the word\n",
        "  \n",
        "  returns casing_ix\n",
        "  '''\n",
        "  if word.istitle():\n",
        "    return case_to_ix['title']\n",
        "  elif word.islower():\n",
        "    return case_to_ix['lower']\n",
        "  elif word.isupper():\n",
        "    return case_to_ix['upper']\n",
        "  elif word.isnumeric():\n",
        "    return case_to_ix['numeric']\n",
        "  return case_to_ix['other']\n",
        "\n",
        "def get_word_ix(word):\n",
        "  '''\n",
        "  takes w and returns the index of the word embedding\n",
        "  out of vocabulary terms return the UNK_WORD and the character embeddings\n",
        "  \n",
        "  returns word_ix\n",
        "  '''\n",
        "  w = word.lower()\n",
        "  w_ix = word_to_ix.get(w)\n",
        "  if w_ix is not None:\n",
        "    return w_ix\n",
        "  return word_to_ix[UNK_WORD]\n",
        "\n",
        "def get_char_ix(char):\n",
        "  char_ix = char_to_ix.get(char)\n",
        "  if char_ix is not None:\n",
        "    return char_ix\n",
        "  return char_to_ix[UNK_CHAR]\n",
        "  \n",
        "def create_character_embeddings(words_df):\n",
        "  '''\n",
        "  Optional function to create pre-trained character embeddings from averaged word embeddings.  In the model we generate them from a uniform random distribution and train.\n",
        "  '''\n",
        "  characters = {}\n",
        "  for i, word_vec in enumerate(words_df.reset_index().values):\n",
        "    for char in word_vec[0]:\n",
        "      if char in characters:\n",
        "        characters[char] = [characters[char][0] + word_vec[1:].astype(float), characters[char][1] + 1]\n",
        "      else:\n",
        "        characters[char] = [word_vec[1:].astype(float), 1]\n",
        "\n",
        "  for key in characters:\n",
        "    characters[key] = np.round(characters[key][0]/characters[key][1],6)\n",
        "    \n",
        "def initialize_word_embeddings(file_name, use_cache=True, debug=True, save_cache=True):\n",
        "  loaded = False\n",
        "  df = None\n",
        "  \n",
        "  if use_cache:\n",
        "    try:\n",
        "      print(\"Attempting to load from cache\")\n",
        "      with pd.HDFStore(embed_store, 'r') as store:\n",
        "        words = store[file_name]\n",
        "      words = pd.read_hdf(embed_store, file_name)\n",
        "      loaded=True\n",
        "      print(\"Loaded successfully\")\n",
        "    except:\n",
        "      print(\"Cache loading failed\")\n",
        "      loaded=False\n",
        "  \n",
        "  if not loaded:\n",
        "    words = pd.read_csv(os.path.join(embed_src, embedding_file), sep=\" \", index_col=0, header=None, quoting=csv.QUOTE_NONE)\n",
        "    # some embeddings come back with word == NaN\n",
        "    words = words[~words.index.isnull()]\n",
        "    # add entries for special tokens\n",
        "    words.loc[UNK_WORD] = [0 for x in words.columns]\n",
        "    words.loc[PAD_WORD] = [0 for x in words.columns]\n",
        "    if save_cache:\n",
        "      with pd.HDFStore(embed_store, 'a') as store:\n",
        "        store[file_name] = words\n",
        "  \n",
        "  word2ix = {word:i for i,word in enumerate(words.index)}\n",
        "  ix2word = {i:word for i,word in enumerate(words.index)}\n",
        "  words = words.to_numpy().astype(float)\n",
        "  \n",
        "  return words, word2ix, ix2word\n",
        "\n",
        "def initialize_character_embeddings(vocab=string.printable):\n",
        "  characters = [x for x in string.printable]\n",
        "  characters += [UNK_CHAR, PAD_CHAR]\n",
        "  char2ix = {ch:i for i, ch in enumerate(characters)}\n",
        "  ix2char = {i:ch for i, ch in enumerate(characters)}\n",
        "  \n",
        "  return characters, char2ix, ix2char\n",
        "\n",
        "def initialize_case_embeddings(vocab=['upper','lower','title','numeric','other']):\n",
        "  case2ix = {case:i for i, case in enumerate(vocab)}\n",
        "  ix2case = {}\n",
        "  cases = []\n",
        "  for k,v in case2ix.items():\n",
        "    this_case = np.zeros(len(case2ix))\n",
        "    this_case[v] = 1\n",
        "    cases.append(this_case)\n",
        "    ix2case[v] = k\n",
        "  cases = np.array(cases)\n",
        "  \n",
        "  return cases, case2ix, ix2case\n",
        "\n",
        "  \n",
        "def initialize_labels(file_name, annotation):\n",
        "  label_list = None\n",
        "  \n",
        "  if annotation == \"BIO\":\n",
        "    domain_labels =  ['B-TITLE', 'I-TITLE']\n",
        "    data = pd.read_csv(os.path.join(data_src, file_name), sep=\"\\t\",  quoting=csv.QUOTE_NONE, header=None, skip_blank_lines=False, engine='python', names =['token', 'pos', 'tree', 'label'])\n",
        "    data.dropna(subset=['label'], inplace=True)\n",
        "    label_list = list(data.label.unique())\n",
        "    label_list += [label for label in domain_labels if label not in label_list]\n",
        "  elif annotation == \"BILOU\":\n",
        "    domain_labels = ['B-TITLE', 'I-TITLE', 'L-TITLE', 'U-TITLE']\n",
        "    data = pd.read_csv(os.path.join(data_src, file_name), header=0, index_col=0,skip_blank_lines=False, engine='python')\n",
        "    label_list = list(np.unique(np.concatenate(data.y.apply(lambda x: np.array(ast.literal_eval(x))).values)))\n",
        "    label_list += [label for label in domain_labels if label not in label_list]\n",
        "  else:\n",
        "    raise Exception(f\"unknown annotation: {annotation}\")\n",
        "    \n",
        "  label2ix = {label:i for i, label in enumerate(label_list)}\n",
        "  ix2label = {i:label for i, label in enumerate(label_list)}\n",
        "  return label_list, label2ix, ix2label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgGc-vs3cWbg",
        "colab_type": "code",
        "outputId": "f543e304-405b-4ff6-fd87-5c7f4b3fc3f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# load embeddings and format\n",
        "words, word_to_ix, ix_to_word = initialize_word_embeddings(embedding_file, use_cache=True)\n",
        "characters, char_to_ix, ix_to_char = initialize_character_embeddings()\n",
        "cases, case_to_ix, ix_to_case = initialize_case_embeddings()\n",
        "labels, label_to_ix, ix_to_label = initialize_labels(real_file, annotation_type)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attempting to load from cache\n",
            "Loaded successfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9-ODReesbH4",
        "colab_type": "text"
      },
      "source": [
        "## Process Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxVpGgDwfGSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def checkPrior(blah):\n",
        "  if (blah.prior is None or blah.prior is np.NaN) and (blah.prior_pos is None or blah.prior_pos is np.NaN):\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "  \n",
        "def phrase2char(w_vec):\n",
        "  '''\n",
        "  This function transforms a sequence of words in index format to a 2d array of character indexes\n",
        "  \n",
        "  w_vec - an iterable of word indexes\n",
        "  \n",
        "  returns np.ndarray of size (len(w_vec), WORD_WIDTH)\n",
        "  '''\n",
        "  phrase_vector = []\n",
        "  for w_ix in w_vec:\n",
        "    char_vector = []\n",
        "    if w_ix not in (word_to_ix[PAD_WORD],word_to_ix[UNK_WORD]):\n",
        "      for char in ix_to_word[w_ix]:\n",
        "        char_vector.append(get_char_ix(char))\n",
        "    phrase_vector.append(np.array(char_vector))\n",
        "  return pad_sequences(phrase_vector, value=char_to_ix[PAD_CHAR], maxlen=WORD_WIDTH, padding='post')\n",
        "\n",
        "def pad_truncate(x,width,pad_token):\n",
        "  if(len(x) > width):\n",
        "    print(f\"Truncating input: {[ix_to_word[ix] for ix in x]}\")\n",
        "    x = x[:256]\n",
        "  return np.pad(x,pad_width=(0,width-len(x)), mode='constant', constant_values=pad_token)\n",
        "\n",
        "def verbosity(str, verbose):\n",
        "  if verbose:\n",
        "    print(str)\n",
        "\n",
        "def sent_to_casing_ix(words):\n",
        "  sentence_vector = []\n",
        "  for word in words:\n",
        "    sentence_vector.append(get_casing_ix(word))\n",
        "  return sentence_vector\n",
        "\n",
        "def sent_to_word_ix(words):\n",
        "  sentence_vector = []\n",
        "  for word in words:\n",
        "    sentence_vector.append(get_word_ix(word))\n",
        "  return sentence_vector\n",
        "\n",
        "def sent_to_label_ix(labels):\n",
        "  label_vector = []\n",
        "  for label in labels:\n",
        "    label_vector.append(label_to_ix[label])\n",
        "  return label_vector\n",
        "\n",
        "def preprocess_data(file_name, annotation, use_cache=True, debug=True, save_cache=True):\n",
        "  '''\n",
        "  Prepares data for model.  It can be used for both training and test data.\n",
        "  \n",
        "  returns pd.DataFrame\n",
        "  '''\n",
        "  clean_name = os.path.join(cache_dir, file_name.replace(\".csv\", \"\").replace(\".\", \"_\"))\n",
        "  loaded = False\n",
        "  output = None\n",
        "      \n",
        "  if use_cache and os.path.exists(f\"{clean_name}_{annotation}_word.npy\"):\n",
        "    verbosity(\"Attempting to load from cache\", debug)\n",
        "    try:\n",
        "      word_vectors = np.load(f\"{clean_name}_{annotation}_word.npy\", allow_pickle=True)\n",
        "      char_vectors = np.load(f\"{clean_name}_{annotation}_char.npy\", allow_pickle=True)\n",
        "      case_vectors = np.load(f\"{clean_name}_{annotation}_case.npy\", allow_pickle=True)\n",
        "      label_vectors = np.load(f\"{clean_name}_{annotation}_label.npy\", allow_pickle=True)\n",
        "      output = [word_vectors, char_vectors, case_vectors, label_vectors]\n",
        "      loaded = True\n",
        "      verbosity(\"Loaded successfully\", debug)\n",
        "    except:\n",
        "      verbosity(\"Loading failed\",debug)\n",
        "      loaded = False\n",
        "  \n",
        "  if not loaded:\n",
        "    if annotation == \"BIO\":\n",
        "      verbosity(f\"Loading raw data file to process labels: {file_name}\", debug)\n",
        "      checkpoint = time.time()  \n",
        "      header = 0\n",
        "      if 'onto' in file_name:\n",
        "        header = None\n",
        "      data = pd.read_csv(os.path.join(data_src, file_name), sep=\"\\t\",  quoting=csv.QUOTE_NONE, header=header, skip_blank_lines=False, engine='python', names =['token', 'pos', 'tree', 'label'])\n",
        "      verbosity(f\"Parsed data loaded: {time.time()-checkpoint} s\", debug)\n",
        "\n",
        "      # see if prior row was a newline\n",
        "      data['prior'] = data.token.shift(1)\n",
        "      data['prior_pos'] = data.pos.shift(1)\n",
        "      # drop empty rows\n",
        "      data = data.loc[~data.token.isnull()]\n",
        "      data.prior = data.apply(checkPrior, axis=1)\n",
        "      data['phrase'] = data.prior.cumsum()\n",
        "\n",
        "      verbosity(\"Processing data into phrase vectors\", debug)\n",
        "      verbosity(\"Step 1: Translating to indexes\", debug)\n",
        "      checkpoint = time.time()\n",
        "      data['word_ix'] = data.token.apply(get_word_ix)\n",
        "      data['case_ix'] = data.token.apply(get_casing_ix)\n",
        "      data['label_ix'] = data.label.apply(lambda x: label_to_ix[x])\n",
        "      verbosity(f\"Step 1: Translated to indexes complete: {time.time()-checkpoint} s\", debug)\n",
        "\n",
        "      verbosity(\"Step 2: Creating phrase vectors\", debug)\n",
        "      verbosity(\"Step 2a: Aggregating phrases\", debug)\n",
        "      checkpoint = time.time()\n",
        "      phrase_vectors = data.groupby('phrase').agg({'token':list, 'word_ix': list, 'case_ix': list, 'label_ix': list})\n",
        "      verbosity(f\"Step 2a: {time.time()-checkpoint} s\", debug)\n",
        "\n",
        "      verbosity(\"Step 2b: Padding word vectors\", debug)\n",
        "      checkpoint = time.time()\n",
        "      phrase_vectors['word_vector'] = phrase_vectors.word_ix.apply(lambda x: pad_truncate(x, SENTENCE_WIDTH, word_to_ix[PAD_WORD]))\n",
        "      verbosity(f\"Step 2b: {time.time()-checkpoint} s\", debug)\n",
        "\n",
        "      verbosity(\"Step 2c: Creating and padding character vectors\", debug)\n",
        "      checkpoint = time.time()\n",
        "      phrase_vectors['char_vector'] = phrase_vectors.word_vector.apply(lambda x: phrase2char(x))\n",
        "      verbosity(f\"Step 2c: {time.time()-checkpoint} s\", debug)\n",
        "\n",
        "      verbosity(f\"Step 2d: Padding case vectors\", debug)\n",
        "      checkpoint = time.time()\n",
        "      phrase_vectors['case_vector'] = phrase_vectors.case_ix.apply(lambda x: pad_truncate(x, SENTENCE_WIDTH, case_to_ix[CASE_PAD_SYMBOL]))\n",
        "      verbosity(f\"Step 2d: {time.time()-checkpoint}\", debug)\n",
        "\n",
        "      verbosity(\"Step 2e: Padding label vectors\", debug)\n",
        "      checkpoint = time.time()\n",
        "      phrase_vectors['label_vector'] = phrase_vectors.label_ix.apply(lambda x: np.expand_dims(pad_truncate(x, SENTENCE_WIDTH, label_to_ix[LABEL_PAD_SYMBOL]), -1))\n",
        "      verbosity(f\"Step 2e: {time.time()-checkpoint} s\", debug)\n",
        "\n",
        "      phrase_vectors.drop(columns=['word_ix', 'case_ix', 'label_ix'], inplace=True)\n",
        "\n",
        "      output = [np.stack(phrase_vectors['word_vector'].values), np.stack(phrase_vectors['char_vector'].values), np.stack(phrase_vectors['case_vector'].values), np.stack(phrase_vectors['label_vector'].values)]\n",
        "    \n",
        "    elif annotation == \"BILOU\":\n",
        "      verbosity(f\"Loading raw data file to process labels: {file_name}\", debug)\n",
        "      checkpoint = time.time()  \n",
        "      data = pd.read_csv(os.path.join(data_src, file_name), header=0, index_col=0,skip_blank_lines=False, engine='python')\n",
        "      data = data[data.x.str.len() > 2]\n",
        "      verbosity(f\"Data loaded: {time.time()-checkpoint} s\", debug)\n",
        "\n",
        "      verbosity(\"Processing data into sentence vectors\", debug)\n",
        "      verbosity(\"Step 1: Translating to indexes\", debug)\n",
        "      checkpoint = time.time()\n",
        "      data.x = data.x.apply(ast.literal_eval)\n",
        "      data.y = data.y.apply(ast.literal_eval)\n",
        "      data['word_vector'] = data.x.apply(lambda x: pad_truncate(sent_to_word_ix(x), SENTENCE_WIDTH, word_to_ix[PAD_WORD]))\n",
        "      data['case_vector'] = data.x.apply(lambda x: pad_truncate(sent_to_casing_ix(x), SENTENCE_WIDTH, case_to_ix[CASE_PAD_SYMBOL]))\n",
        "      data['label_vector'] = data.y.apply(lambda x: pad_truncate(sent_to_label_ix(x), SENTENCE_WIDTH, label_to_ix[LABEL_PAD_SYMBOL]))\n",
        "      print(\"Processing character vectors\")\n",
        "      data['char_vector'] = data.word_vector.apply(lambda x: phrase2char(x))\n",
        "      verbosity(f\"Step 1: Translated to indexes complete: {time.time()-checkpoint} s\", debug)\n",
        "\n",
        "      output = [np.stack(data[\"word_vector\"].values), np.stack(data[\"char_vector\"].values), np.stack(data[\"case_vector\"].values), np.expand_dims(np.stack(data[\"label_vector\"].values),-1)]\n",
        "    \n",
        "    else:\n",
        "      raise Exception(f\"unkown annotation: {annotation}\")\n",
        "    \n",
        "    if save_cache:\n",
        "      verbosity(\"Saving data to disk\", debug)\n",
        "      checkpoint = time.time()\n",
        "      # saving in multi parts because training data causes a memory error\n",
        "      np.save(f\"{clean_name}_{annotation}_word\", output[0], allow_pickle=True)\n",
        "      np.save(f\"{clean_name}_{annotation}_char\", output[1], allow_pickle=True)\n",
        "      np.save(f\"{clean_name}_{annotation}_case\", output[2], allow_pickle=True)\n",
        "      np.save(f\"{clean_name}_{annotation}_label\", output[3], allow_pickle=True)\n",
        "      verbosity(f\"Saved to disk: {time.time()-checkpoint} s\", debug)\n",
        "  \n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApHe1T0-7rwf",
        "colab_type": "text"
      },
      "source": [
        "## Prepare domain data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSo8yT-m9Yzl",
        "colab_type": "code",
        "outputId": "cdd7dd03-4cf4-4535-b8e5-f6506c51a394",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "real_data = preprocess_data(real_file, annotation_type, use_cache=False,save_cache=False)\n",
        "print(real_data[0].shape, real_data[1].shape, real_data[2].shape, real_data[3].shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading raw data file to process labels: bios-tagged-final-flat_bilou.csv\n",
            "Data loaded: 0.013188838958740234 s\n",
            "Processing data into sentence vectors\n",
            "Step 1: Translating to indexes\n",
            "Processing character vectors\n",
            "Step 1: Translated to indexes complete: 0.7101879119873047 s\n",
            "(708, 256) (708, 256, 52) (708, 256) (708, 256, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE2x6aK1mfij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_dev_test_split(data, test_size, train_size):\n",
        "  all_choices = np.arange(0,data[0].shape[0])\n",
        "  test_choices = np.random.choice(a=all_choices, size=int(np.round(data[0].shape[0]*test_size)), replace=False)\n",
        "  real_test_data = [data[0][test_choices], data[1][test_choices], data[2][test_choices], data[3][test_choices]]\n",
        "  not_test_choices = np.setdiff1d(all_choices,test_choices)\n",
        "  not_test_data = data[0][not_test_choices], data[1][not_test_choices], data[2][not_test_choices], data[3][not_test_choices]\n",
        "  train_choices = np.random.randint(0,not_test_data[0].shape[0], size=int(np.round(not_test_data[0].shape[0]*train_size)))\n",
        "  train_choices = np.random.choice(a=not_test_choices, size=int(np.round(not_test_choices.shape[0]*train_size)), replace=False)\n",
        "  real_train_data = [data[0][train_choices], data[1][train_choices], data[2][train_choices], data[3][train_choices]]\n",
        "  dev_choices = np.setdiff1d(not_test_choices, train_choices)\n",
        "  real_dev_data = [data[0][dev_choices], data[1][dev_choices], data[2][dev_choices], data[3][dev_choices]]\n",
        "\n",
        "  print(f\"Original shape: {data[0].shape}\")\n",
        "  print(f\"Train shape: {real_train_data[0].shape}\")\n",
        "  print(f\"Dev shape: {real_dev_data[0].shape}\")\n",
        "  print(f\"Test shape: {real_test_data[0].shape}\")\n",
        "\n",
        "  return real_test_data, real_dev_data, real_train_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK7ahBZjmjf3",
        "colab_type": "code",
        "outputId": "91e86f67-7715-4dfb-ac81-3b00794cc115",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "rtrain, rdev, rtest = train_dev_test_split(real_data, 0.435, 0.75)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original shape: (708, 256)\n",
            "Train shape: (300, 256)\n",
            "Dev shape: (100, 256)\n",
            "Test shape: (308, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9EoodmDDgbI",
        "colab_type": "text"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg8mZc-1DlD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/mxhofer/Named-Entity-Recognition-BidirectionalLSTM-CNN-CoNLL/blob/master/nn_CoNLL.ipynb\n",
        "\n",
        "def buildModel(labels, wordEmbeddings, caseEmbeddings, characterEmbeddings=None):\n",
        "  \n",
        "  # character - input\n",
        "  character_input = Input(shape=(None, WORD_LENGTH,), name=\"Character_input\")\n",
        "  embed_char_out = TimeDistributed(\n",
        "      Embedding(CHAR_VOCAB,\n",
        "                CHAR_EMBEDDING_DIM,\n",
        "                embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)),name=\"Character_embedding\")(character_input)\n",
        "\n",
        "  dropout = Dropout(DROPOUT)(embed_char_out)\n",
        "\n",
        "  ## character - CNN\n",
        "  conv1d_out = TimeDistributed(Conv1D(kernel_size=CONV_SIZE,\n",
        "                                      filters=CONV_FILTERS,\n",
        "                                      padding='same',\n",
        "                                      activation='tanh',\n",
        "                                      strides=CONV_STRIDE), name=\"Convolution\")(dropout)\n",
        "  maxpool_out = TimeDistributed(MaxPooling1D(CONV_WINDOW), name=\"Maxpool\")(conv1d_out)\n",
        "  char = TimeDistributed(Flatten(), name=\"Flatten\")(maxpool_out)\n",
        "  char = Dropout(DROPOUT)(char)\n",
        "\n",
        "  # word - input\n",
        "  words_input = Input(shape=(None,), dtype='int32', name='words_input')\n",
        "  words = Embedding(input_dim=wordEmbeddings.shape[0],\n",
        "                    output_dim=wordEmbeddings.shape[1],\n",
        "                    weights=[wordEmbeddings],\n",
        "                    trainable=False)(words_input)\n",
        "\n",
        "  # case - input\n",
        "  casing_input = Input(shape=(None,), dtype='int32', name='casing_input')\n",
        "  casing = Embedding(input_dim=caseEmbeddings.shape[0],\n",
        "                     output_dim=caseEmbeddings.shape[1],\n",
        "                     weights=[caseEmbeddings],\n",
        "                     trainable=False)(casing_input)\n",
        "  \n",
        "  # character + word + case -> biLSTM\n",
        "  output = concatenate([words, casing, char])\n",
        "  output = Bidirectional(LSTM(LSTM_STATE_SIZE, \n",
        "                              return_sequences=True, \n",
        "                              dropout=DROPOUT,\n",
        "                              recurrent_dropout=RECURRENT_DROPOUT\n",
        "                             ), name=\"biLSTM\")(output)\n",
        "  \n",
        "  # output\n",
        "  output = TimeDistributed(Dense(len(labels), activation='softmax'),name=\"softmax\")(output)\n",
        "\n",
        "  # finalize\n",
        "  model = Model(inputs=[words_input, character_input, casing_input], outputs=[output])\n",
        "\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer=Nadam())\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJpVSJwu9o8u",
        "colab_type": "text"
      },
      "source": [
        "# Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6CpwuNAYgv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_metrics(model, data, save_name=None):\n",
        "  predictions = model.predict(data[:3])\n",
        "  y = data[3].reshape(data[3].shape[0],data[3].shape[1])\n",
        "  \n",
        "  pf = np.argmax(predictions, axis=2).flatten()\n",
        "  af = data[3].flatten()\n",
        "  \n",
        "  metrics = []\n",
        "  metrics = pd.DataFrame(columns=['Label', 'Support', 'Precision', 'Recall', \"F1\"])\n",
        "  for i, label in enumerate(labels):\n",
        "    support = np.where(af == i)\n",
        "    tp = np.sum(pf[support] == af[support])\n",
        "\n",
        "    precision = None\n",
        "    if pf[np.where(pf == i)].shape[0] == 0:\n",
        "      precision = 0.0\n",
        "    else:\n",
        "      precision = tp/pf[np.where(pf == i)].shape[0]\n",
        "      \n",
        "    recall = tp/af[support].shape[0]\n",
        "    \n",
        "    f1 = None\n",
        "    if precision + recall == 0:\n",
        "      f1 = 0\n",
        "    else:\n",
        "      f1 = 2*precision*recall/(precision+recall)\n",
        "\n",
        "    metrics = metrics.append({'Label': ix_to_label[i], 'Support':af[support].shape[0], 'Precision': precision, 'Recall':recall, 'F1':f1}, ignore_index=True)\n",
        "  \n",
        "  metrics = metrics.append({'Label': 'micro',\n",
        "                  'Support': metrics.Support.sum(),\n",
        "                  'Precision': (metrics.Precision*metrics.Support/pf.shape[0]).sum(),\n",
        "                  'Recall': (metrics.Recall*metrics.Support/pf.shape[0]).sum(),\n",
        "                  'F1': (metrics.F1*metrics.Support/pf.shape[0]).sum()\n",
        "                           },\n",
        "                 ignore_index=True)\n",
        "  metrics = metrics.set_index('Label')\n",
        "  if save_name is not None:\n",
        "    print(\"saving\")\n",
        "    metrics.to_csv(os.path.join(model_dir, save_name))\n",
        "  display(metrics)\n",
        "  return predictions\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW5XAFSL8Ctz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ece9623c-926b-4962-fb70-7fdf7329fe1f"
      },
      "source": [
        "print(\"Building model\")\n",
        "for size in real_training_sizes:\n",
        "  new_model = buildModel(labels, words, cases)\n",
        "  if size == np.min(real_training_sizes):\n",
        "    print(new_model.summary())\n",
        "    \n",
        "  t_word = rtrain[0][:size]\n",
        "  t_char = rtrain[1][:size]\n",
        "  t_case = rtrain[2][:size]\n",
        "  t_labels = rtrain[3][:size]\n",
        "  \n",
        "  print(new_model.evaluate(rdev[:3], rdev[3]))\n",
        "  new_model.fit([t_word, t_char, t_case], t_labels,\n",
        "              validation_data = (rdev[:3], rdev[3]),\n",
        "              epochs=EPOCHS,\n",
        "              initial_epoch=0,\n",
        "              batch_size=10,\n",
        "              callbacks=[EarlyStopping(min_delta=0), ModelCheckpoint(model_path)])\n",
        "  test_pred = get_metrics(new_model, rtest, save_name=model_name + f'_{size}.csv')\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0803 07:59:40.898433 139854150084480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0803 07:59:40.903131 139854150084480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0803 07:59:40.904549 139854150084480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Building model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0803 07:59:40.930281 139854150084480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0803 07:59:40.941917 139854150084480 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0803 07:59:40.996485 139854150084480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0803 07:59:41.051987 139854150084480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0803 07:59:42.821901 139854150084480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Character_input (InputLayer)    (None, None, 52)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Character_embedding (TimeDistri (None, None, 52, 30) 3000        Character_input[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, None, 52, 30) 0           Character_embedding[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Convolution (TimeDistributed)   (None, None, 52, 30) 2730        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "Maxpool (TimeDistributed)       (None, None, 1, 30)  0           Convolution[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "words_input (InputLayer)        (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "casing_input (InputLayer)       (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Flatten (TimeDistributed)       (None, None, 30)     0           Maxpool[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 50)     19999950    words_input[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, None, 5)      25          casing_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, None, 30)     0           Flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, None, 85)     0           embedding_2[0][0]                \n",
            "                                                                 embedding_3[0][0]                \n",
            "                                                                 dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "biLSTM (Bidirectional)          (None, None, 400)    457600      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "softmax (TimeDistributed)       (None, None, 39)     15639       biLSTM[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 20,478,944\n",
            "Trainable params: 478,969\n",
            "Non-trainable params: 19,999,975\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "100/100 [==============================] - 2s 23ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0803 07:59:45.300086 139854150084480 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.742018337249756\n",
            "Train on 10 samples, validate on 100 samples\n",
            "Epoch 1/20\n",
            "10/10 [==============================] - 5s 524ms/step - loss: 3.7373 - val_loss: 3.2296\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 3s 323ms/step - loss: 3.2875 - val_loss: 2.6797\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 3s 319ms/step - loss: 2.8164 - val_loss: 1.1485\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 3s 317ms/step - loss: 1.1278 - val_loss: 0.3563\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 3s 332ms/step - loss: 0.2461 - val_loss: 0.3242\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 3s 330ms/step - loss: 0.2174 - val_loss: 0.2969\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 3s 331ms/step - loss: 0.2010 - val_loss: 0.2701\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 3s 325ms/step - loss: 0.1789 - val_loss: 0.2453\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 3s 327ms/step - loss: 0.1638 - val_loss: 0.2230\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 3s 325ms/step - loss: 0.1476 - val_loss: 0.2045\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 3s 326ms/step - loss: 0.1358 - val_loss: 0.1944\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 0.1304 - val_loss: 0.1864\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 3s 328ms/step - loss: 0.1238 - val_loss: 0.1811\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 3s 330ms/step - loss: 0.1201 - val_loss: 0.1759\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 0.1196 - val_loss: 0.1816\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in long_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "saving\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Support</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>B-DATE</th>\n",
              "      <td>145</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-GPE</th>\n",
              "      <td>6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-LAW</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-MONEY</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-NORP</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-ORG</th>\n",
              "      <td>381</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-PERCENT</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-PERSON</th>\n",
              "      <td>43</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-PRODUCT</th>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-TITLE</th>\n",
              "      <td>136</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-DATE</th>\n",
              "      <td>118</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-GPE</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-LAW</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-MONEY</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-ORG</th>\n",
              "      <td>590</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-PERSON</th>\n",
              "      <td>34</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-PRODUCT</th>\n",
              "      <td>11</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-TITLE</th>\n",
              "      <td>108</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-DATE</th>\n",
              "      <td>145</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-GPE</th>\n",
              "      <td>6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-LAW</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-MONEY</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-NORP</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-ORG</th>\n",
              "      <td>381</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-PERCENT</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-PERSON</th>\n",
              "      <td>43</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-PRODUCT</th>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-TITLE</th>\n",
              "      <td>136</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>O</th>\n",
              "      <td>73965</td>\n",
              "      <td>0.963086</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.981196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-CARDINAL</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-DATE</th>\n",
              "      <td>96</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-GPE</th>\n",
              "      <td>19</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-LOC</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-NORP</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-ORDINAL</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-ORG</th>\n",
              "      <td>106</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-PERSON</th>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-PRODUCT</th>\n",
              "      <td>12</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-TITLE</th>\n",
              "      <td>196</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>micro</th>\n",
              "      <td>76800</td>\n",
              "      <td>0.927535</td>\n",
              "      <td>0.963086</td>\n",
              "      <td>0.944976</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Support  Precision    Recall        F1\n",
              "Label                                            \n",
              "B-DATE         145   0.000000  0.000000         0\n",
              "B-GPE            6   0.000000  0.000000         0\n",
              "B-LAW            2   0.000000  0.000000         0\n",
              "B-MONEY          3   0.000000  0.000000         0\n",
              "B-NORP           0   0.000000       NaN       NaN\n",
              "B-ORG          381   0.000000  0.000000         0\n",
              "B-PERCENT        0   0.000000       NaN       NaN\n",
              "B-PERSON        43   0.000000  0.000000         0\n",
              "B-PRODUCT        7   0.000000  0.000000         0\n",
              "B-TITLE        136   0.000000  0.000000         0\n",
              "I-DATE         118   0.000000  0.000000         0\n",
              "I-GPE            3   0.000000  0.000000         0\n",
              "I-LAW            1   0.000000  0.000000         0\n",
              "I-MONEY          2   0.000000  0.000000         0\n",
              "I-ORG          590   0.000000  0.000000         0\n",
              "I-PERSON        34   0.000000  0.000000         0\n",
              "I-PRODUCT       11   0.000000  0.000000         0\n",
              "I-TITLE        108   0.000000  0.000000         0\n",
              "L-DATE         145   0.000000  0.000000         0\n",
              "L-GPE            6   0.000000  0.000000         0\n",
              "L-LAW            2   0.000000  0.000000         0\n",
              "L-MONEY          3   0.000000  0.000000         0\n",
              "L-NORP           0   0.000000       NaN       NaN\n",
              "L-ORG          381   0.000000  0.000000         0\n",
              "L-PERCENT        0   0.000000       NaN       NaN\n",
              "L-PERSON        43   0.000000  0.000000         0\n",
              "L-PRODUCT        7   0.000000  0.000000         0\n",
              "L-TITLE        136   0.000000  0.000000         0\n",
              "O            73965   0.963086  1.000000  0.981196\n",
              "U-CARDINAL       2   0.000000  0.000000         0\n",
              "U-DATE          96   0.000000  0.000000         0\n",
              "U-GPE           19   0.000000  0.000000         0\n",
              "U-LOC            0   0.000000       NaN       NaN\n",
              "U-NORP           3   0.000000  0.000000         0\n",
              "U-ORDINAL        2   0.000000  0.000000         0\n",
              "U-ORG          106   0.000000  0.000000         0\n",
              "U-PERSON        86   0.000000  0.000000         0\n",
              "U-PRODUCT       12   0.000000  0.000000         0\n",
              "U-TITLE        196   0.000000  0.000000         0\n",
              "micro        76800   0.927535  0.963086  0.944976"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 2s 17ms/step\n",
            "3.6880867671966553\n",
            "Train on 25 samples, validate on 100 samples\n",
            "Epoch 1/20\n",
            "25/25 [==============================] - 8s 315ms/step - loss: 3.2859 - val_loss: 1.1312\n",
            "Epoch 2/20\n",
            "25/25 [==============================] - 5s 211ms/step - loss: 0.6135 - val_loss: 0.2775\n",
            "Epoch 3/20\n",
            "25/25 [==============================] - 5s 213ms/step - loss: 0.1996 - val_loss: 0.2210\n",
            "Epoch 4/20\n",
            "25/25 [==============================] - 6s 222ms/step - loss: 0.1601 - val_loss: 0.1763\n",
            "Epoch 5/20\n",
            "25/25 [==============================] - 5s 219ms/step - loss: 0.1399 - val_loss: 0.1651\n",
            "Epoch 6/20\n",
            "25/25 [==============================] - 5s 215ms/step - loss: 0.1788 - val_loss: 0.2484\n",
            "saving\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in long_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Support</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>B-DATE</th>\n",
              "      <td>145</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-GPE</th>\n",
              "      <td>6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-LAW</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-MONEY</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-NORP</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-ORG</th>\n",
              "      <td>381</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-PERCENT</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-PERSON</th>\n",
              "      <td>43</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-PRODUCT</th>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-TITLE</th>\n",
              "      <td>136</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-DATE</th>\n",
              "      <td>118</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-GPE</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-LAW</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-MONEY</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-ORG</th>\n",
              "      <td>590</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-PERSON</th>\n",
              "      <td>34</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-PRODUCT</th>\n",
              "      <td>11</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-TITLE</th>\n",
              "      <td>108</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-DATE</th>\n",
              "      <td>145</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-GPE</th>\n",
              "      <td>6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-LAW</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-MONEY</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-NORP</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-ORG</th>\n",
              "      <td>381</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-PERCENT</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-PERSON</th>\n",
              "      <td>43</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-PRODUCT</th>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-TITLE</th>\n",
              "      <td>136</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>O</th>\n",
              "      <td>73965</td>\n",
              "      <td>0.963086</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.981196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-CARDINAL</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-DATE</th>\n",
              "      <td>96</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-GPE</th>\n",
              "      <td>19</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-LOC</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-NORP</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-ORDINAL</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-ORG</th>\n",
              "      <td>106</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-PERSON</th>\n",
              "      <td>86</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-PRODUCT</th>\n",
              "      <td>12</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-TITLE</th>\n",
              "      <td>196</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>micro</th>\n",
              "      <td>76800</td>\n",
              "      <td>0.927535</td>\n",
              "      <td>0.963086</td>\n",
              "      <td>0.944976</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Support  Precision    Recall        F1\n",
              "Label                                            \n",
              "B-DATE         145   0.000000  0.000000         0\n",
              "B-GPE            6   0.000000  0.000000         0\n",
              "B-LAW            2   0.000000  0.000000         0\n",
              "B-MONEY          3   0.000000  0.000000         0\n",
              "B-NORP           0   0.000000       NaN       NaN\n",
              "B-ORG          381   0.000000  0.000000         0\n",
              "B-PERCENT        0   0.000000       NaN       NaN\n",
              "B-PERSON        43   0.000000  0.000000         0\n",
              "B-PRODUCT        7   0.000000  0.000000         0\n",
              "B-TITLE        136   0.000000  0.000000         0\n",
              "I-DATE         118   0.000000  0.000000         0\n",
              "I-GPE            3   0.000000  0.000000         0\n",
              "I-LAW            1   0.000000  0.000000         0\n",
              "I-MONEY          2   0.000000  0.000000         0\n",
              "I-ORG          590   0.000000  0.000000         0\n",
              "I-PERSON        34   0.000000  0.000000         0\n",
              "I-PRODUCT       11   0.000000  0.000000         0\n",
              "I-TITLE        108   0.000000  0.000000         0\n",
              "L-DATE         145   0.000000  0.000000         0\n",
              "L-GPE            6   0.000000  0.000000         0\n",
              "L-LAW            2   0.000000  0.000000         0\n",
              "L-MONEY          3   0.000000  0.000000         0\n",
              "L-NORP           0   0.000000       NaN       NaN\n",
              "L-ORG          381   0.000000  0.000000         0\n",
              "L-PERCENT        0   0.000000       NaN       NaN\n",
              "L-PERSON        43   0.000000  0.000000         0\n",
              "L-PRODUCT        7   0.000000  0.000000         0\n",
              "L-TITLE        136   0.000000  0.000000         0\n",
              "O            73965   0.963086  1.000000  0.981196\n",
              "U-CARDINAL       2   0.000000  0.000000         0\n",
              "U-DATE          96   0.000000  0.000000         0\n",
              "U-GPE           19   0.000000  0.000000         0\n",
              "U-LOC            0   0.000000       NaN       NaN\n",
              "U-NORP           3   0.000000  0.000000         0\n",
              "U-ORDINAL        2   0.000000  0.000000         0\n",
              "U-ORG          106   0.000000  0.000000         0\n",
              "U-PERSON        86   0.000000  0.000000         0\n",
              "U-PRODUCT       12   0.000000  0.000000         0\n",
              "U-TITLE        196   0.000000  0.000000         0\n",
              "micro        76800   0.927535  0.963086  0.944976"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 2s 21ms/step\n",
            "3.6405712604522704\n",
            "Train on 50 samples, validate on 100 samples\n",
            "Epoch 1/20\n",
            "50/50 [==============================] - 10s 200ms/step - loss: 2.0724 - val_loss: 0.3010\n",
            "Epoch 2/20\n",
            "50/50 [==============================] - 7s 148ms/step - loss: 0.1841 - val_loss: 0.1798\n",
            "Epoch 3/20\n",
            "50/50 [==============================] - 8s 150ms/step - loss: 0.1347 - val_loss: 0.1652\n",
            "Epoch 4/20\n",
            "50/50 [==============================] - 7s 146ms/step - loss: 0.1176 - val_loss: 0.1504\n",
            "Epoch 5/20\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.1087 - val_loss: 0.1436\n",
            "Epoch 6/20\n",
            "50/50 [==============================] - 7s 149ms/step - loss: 0.1025 - val_loss: 0.1343\n",
            "Epoch 7/20\n",
            "50/50 [==============================] - 7s 150ms/step - loss: 0.0954 - val_loss: 0.1277\n",
            "Epoch 8/20\n",
            "50/50 [==============================] - 7s 148ms/step - loss: 0.0889 - val_loss: 0.1203\n",
            "Epoch 9/20\n",
            "50/50 [==============================] - 8s 150ms/step - loss: 0.0895 - val_loss: 0.1165\n",
            "Epoch 10/20\n",
            "50/50 [==============================] - 7s 148ms/step - loss: 0.0804 - val_loss: 0.1130\n",
            "Epoch 11/20\n",
            "50/50 [==============================] - 7s 150ms/step - loss: 0.0827 - val_loss: 0.1034\n",
            "Epoch 12/20\n",
            "50/50 [==============================] - 7s 147ms/step - loss: 0.0707 - val_loss: 0.1000\n",
            "Epoch 13/20\n",
            "50/50 [==============================] - 7s 150ms/step - loss: 0.0642 - val_loss: 0.0982\n",
            "Epoch 14/20\n",
            "50/50 [==============================] - 8s 150ms/step - loss: 0.0594 - val_loss: 0.1106\n",
            "saving\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in long_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Support</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>B-DATE</th>\n",
              "      <td>145</td>\n",
              "      <td>0.763158</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.316940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-GPE</th>\n",
              "      <td>6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-LAW</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-MONEY</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-NORP</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-ORG</th>\n",
              "      <td>381</td>\n",
              "      <td>0.726027</td>\n",
              "      <td>0.139108</td>\n",
              "      <td>0.233480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-PERCENT</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-PERSON</th>\n",
              "      <td>43</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-PRODUCT</th>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-TITLE</th>\n",
              "      <td>136</td>\n",
              "      <td>0.504854</td>\n",
              "      <td>0.382353</td>\n",
              "      <td>0.435146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-DATE</th>\n",
              "      <td>118</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-GPE</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-LAW</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-MONEY</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-ORG</th>\n",
              "      <td>590</td>\n",
              "      <td>0.560440</td>\n",
              "      <td>0.086441</td>\n",
              "      <td>0.149780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-PERSON</th>\n",
              "      <td>34</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-PRODUCT</th>\n",
              "      <td>11</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-TITLE</th>\n",
              "      <td>108</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-DATE</th>\n",
              "      <td>145</td>\n",
              "      <td>0.627119</td>\n",
              "      <td>0.255172</td>\n",
              "      <td>0.362745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-GPE</th>\n",
              "      <td>6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-LAW</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-MONEY</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-NORP</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-ORG</th>\n",
              "      <td>381</td>\n",
              "      <td>0.808219</td>\n",
              "      <td>0.309711</td>\n",
              "      <td>0.447818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-PERCENT</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-PERSON</th>\n",
              "      <td>43</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-PRODUCT</th>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-TITLE</th>\n",
              "      <td>136</td>\n",
              "      <td>0.903226</td>\n",
              "      <td>0.205882</td>\n",
              "      <td>0.335329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>O</th>\n",
              "      <td>73965</td>\n",
              "      <td>0.971918</td>\n",
              "      <td>0.999959</td>\n",
              "      <td>0.985739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-CARDINAL</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-DATE</th>\n",
              "      <td>96</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.156250</td>\n",
              "      <td>0.227273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-GPE</th>\n",
              "      <td>19</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-LOC</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-NORP</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-ORDINAL</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-ORG</th>\n",
              "      <td>106</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-PERSON</th>\n",
              "      <td>86</td>\n",
              "      <td>0.156250</td>\n",
              "      <td>0.058140</td>\n",
              "      <td>0.084746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-PRODUCT</th>\n",
              "      <td>12</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-TITLE</th>\n",
              "      <td>196</td>\n",
              "      <td>0.822222</td>\n",
              "      <td>0.377551</td>\n",
              "      <td>0.517483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>micro</th>\n",
              "      <td>76800</td>\n",
              "      <td>0.955870</td>\n",
              "      <td>0.969063</td>\n",
              "      <td>0.958230</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Support  Precision    Recall        F1\n",
              "Label                                            \n",
              "B-DATE         145   0.763158  0.200000  0.316940\n",
              "B-GPE            6   0.000000  0.000000  0.000000\n",
              "B-LAW            2   0.000000  0.000000  0.000000\n",
              "B-MONEY          3   0.000000  0.000000  0.000000\n",
              "B-NORP           0   0.000000       NaN       NaN\n",
              "B-ORG          381   0.726027  0.139108  0.233480\n",
              "B-PERCENT        0   0.000000       NaN       NaN\n",
              "B-PERSON        43   0.000000  0.000000  0.000000\n",
              "B-PRODUCT        7   0.000000  0.000000  0.000000\n",
              "B-TITLE        136   0.504854  0.382353  0.435146\n",
              "I-DATE         118   0.000000  0.000000  0.000000\n",
              "I-GPE            3   0.000000  0.000000  0.000000\n",
              "I-LAW            1   0.000000  0.000000  0.000000\n",
              "I-MONEY          2   0.000000  0.000000  0.000000\n",
              "I-ORG          590   0.560440  0.086441  0.149780\n",
              "I-PERSON        34   0.000000  0.000000  0.000000\n",
              "I-PRODUCT       11   0.000000  0.000000  0.000000\n",
              "I-TITLE        108   0.000000  0.000000  0.000000\n",
              "L-DATE         145   0.627119  0.255172  0.362745\n",
              "L-GPE            6   0.000000  0.000000  0.000000\n",
              "L-LAW            2   0.000000  0.000000  0.000000\n",
              "L-MONEY          3   0.000000  0.000000  0.000000\n",
              "L-NORP           0   0.000000       NaN       NaN\n",
              "L-ORG          381   0.808219  0.309711  0.447818\n",
              "L-PERCENT        0   0.000000       NaN       NaN\n",
              "L-PERSON        43   0.000000  0.000000  0.000000\n",
              "L-PRODUCT        7   0.000000  0.000000  0.000000\n",
              "L-TITLE        136   0.903226  0.205882  0.335329\n",
              "O            73965   0.971918  0.999959  0.985739\n",
              "U-CARDINAL       2   0.000000  0.000000  0.000000\n",
              "U-DATE          96   0.416667  0.156250  0.227273\n",
              "U-GPE           19   0.000000  0.000000  0.000000\n",
              "U-LOC            0   0.000000       NaN       NaN\n",
              "U-NORP           3   0.000000  0.000000  0.000000\n",
              "U-ORDINAL        2   0.000000  0.000000  0.000000\n",
              "U-ORG          106   0.000000  0.000000  0.000000\n",
              "U-PERSON        86   0.156250  0.058140  0.084746\n",
              "U-PRODUCT       12   0.000000  0.000000  0.000000\n",
              "U-TITLE        196   0.822222  0.377551  0.517483\n",
              "micro        76800   0.955870  0.969063  0.958230"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 3s 25ms/step\n",
            "3.667499179840088\n",
            "Train on 100 samples, validate on 100 samples\n",
            "Epoch 1/20\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 1.1333 - val_loss: 0.1928\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.1436 - val_loss: 0.1518\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.1225 - val_loss: 0.1351\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.1091 - val_loss: 0.1212\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 13s 128ms/step - loss: 0.0975 - val_loss: 0.1074\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.0865 - val_loss: 0.0942\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 13s 131ms/step - loss: 0.0811 - val_loss: 0.0862\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.0693 - val_loss: 0.0837\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 13s 129ms/step - loss: 0.0644 - val_loss: 0.0746\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.0568 - val_loss: 0.0695\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 13s 128ms/step - loss: 0.0507 - val_loss: 0.0772\n",
            "saving\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in long_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Support</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>B-DATE</th>\n",
              "      <td>145</td>\n",
              "      <td>0.725146</td>\n",
              "      <td>0.855172</td>\n",
              "      <td>0.784810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-GPE</th>\n",
              "      <td>6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-LAW</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-MONEY</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-NORP</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-ORG</th>\n",
              "      <td>381</td>\n",
              "      <td>0.658879</td>\n",
              "      <td>0.370079</td>\n",
              "      <td>0.473950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-PERCENT</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-PERSON</th>\n",
              "      <td>43</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>0.534884</td>\n",
              "      <td>0.686567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-PRODUCT</th>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-TITLE</th>\n",
              "      <td>136</td>\n",
              "      <td>0.609756</td>\n",
              "      <td>0.735294</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-DATE</th>\n",
              "      <td>118</td>\n",
              "      <td>0.718182</td>\n",
              "      <td>0.669492</td>\n",
              "      <td>0.692982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-GPE</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-LAW</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-MONEY</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-ORG</th>\n",
              "      <td>590</td>\n",
              "      <td>0.629353</td>\n",
              "      <td>0.428814</td>\n",
              "      <td>0.510081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-PERSON</th>\n",
              "      <td>34</td>\n",
              "      <td>0.964286</td>\n",
              "      <td>0.794118</td>\n",
              "      <td>0.870968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-PRODUCT</th>\n",
              "      <td>11</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-TITLE</th>\n",
              "      <td>108</td>\n",
              "      <td>0.141414</td>\n",
              "      <td>0.648148</td>\n",
              "      <td>0.232172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-DATE</th>\n",
              "      <td>145</td>\n",
              "      <td>0.753968</td>\n",
              "      <td>0.655172</td>\n",
              "      <td>0.701107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-GPE</th>\n",
              "      <td>6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-LAW</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-MONEY</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-NORP</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-ORG</th>\n",
              "      <td>381</td>\n",
              "      <td>0.694789</td>\n",
              "      <td>0.734908</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-PERCENT</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-PERSON</th>\n",
              "      <td>43</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.209302</td>\n",
              "      <td>0.346154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-PRODUCT</th>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-TITLE</th>\n",
              "      <td>136</td>\n",
              "      <td>0.495192</td>\n",
              "      <td>0.757353</td>\n",
              "      <td>0.598837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>O</th>\n",
              "      <td>73965</td>\n",
              "      <td>0.993152</td>\n",
              "      <td>0.996052</td>\n",
              "      <td>0.994600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-CARDINAL</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-DATE</th>\n",
              "      <td>96</td>\n",
              "      <td>0.605634</td>\n",
              "      <td>0.447917</td>\n",
              "      <td>0.514970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-GPE</th>\n",
              "      <td>19</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>0.272727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-LOC</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-NORP</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-ORDINAL</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-ORG</th>\n",
              "      <td>106</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.132075</td>\n",
              "      <td>0.225806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-PERSON</th>\n",
              "      <td>86</td>\n",
              "      <td>0.682927</td>\n",
              "      <td>0.651163</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-PRODUCT</th>\n",
              "      <td>12</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-TITLE</th>\n",
              "      <td>196</td>\n",
              "      <td>0.868132</td>\n",
              "      <td>0.403061</td>\n",
              "      <td>0.550523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>micro</th>\n",
              "      <td>76800</td>\n",
              "      <td>0.980674</td>\n",
              "      <td>0.978802</td>\n",
              "      <td>0.978274</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Support  Precision    Recall        F1\n",
              "Label                                            \n",
              "B-DATE         145   0.725146  0.855172  0.784810\n",
              "B-GPE            6   0.000000  0.000000  0.000000\n",
              "B-LAW            2   0.000000  0.000000  0.000000\n",
              "B-MONEY          3   0.000000  0.000000  0.000000\n",
              "B-NORP           0   0.000000       NaN       NaN\n",
              "B-ORG          381   0.658879  0.370079  0.473950\n",
              "B-PERCENT        0   0.000000       NaN       NaN\n",
              "B-PERSON        43   0.958333  0.534884  0.686567\n",
              "B-PRODUCT        7   0.000000  0.000000  0.000000\n",
              "B-TITLE        136   0.609756  0.735294  0.666667\n",
              "I-DATE         118   0.718182  0.669492  0.692982\n",
              "I-GPE            3   0.000000  0.000000  0.000000\n",
              "I-LAW            1   0.000000  0.000000  0.000000\n",
              "I-MONEY          2   0.000000  0.000000  0.000000\n",
              "I-ORG          590   0.629353  0.428814  0.510081\n",
              "I-PERSON        34   0.964286  0.794118  0.870968\n",
              "I-PRODUCT       11   0.000000  0.000000  0.000000\n",
              "I-TITLE        108   0.141414  0.648148  0.232172\n",
              "L-DATE         145   0.753968  0.655172  0.701107\n",
              "L-GPE            6   0.000000  0.000000  0.000000\n",
              "L-LAW            2   0.000000  0.000000  0.000000\n",
              "L-MONEY          3   0.000000  0.000000  0.000000\n",
              "L-NORP           0   0.000000       NaN       NaN\n",
              "L-ORG          381   0.694789  0.734908  0.714286\n",
              "L-PERCENT        0   0.000000       NaN       NaN\n",
              "L-PERSON        43   1.000000  0.209302  0.346154\n",
              "L-PRODUCT        7   0.000000  0.000000  0.000000\n",
              "L-TITLE        136   0.495192  0.757353  0.598837\n",
              "O            73965   0.993152  0.996052  0.994600\n",
              "U-CARDINAL       2   0.000000  0.000000  0.000000\n",
              "U-DATE          96   0.605634  0.447917  0.514970\n",
              "U-GPE           19   1.000000  0.157895  0.272727\n",
              "U-LOC            0   0.000000       NaN       NaN\n",
              "U-NORP           3   0.000000  0.000000  0.000000\n",
              "U-ORDINAL        2   0.000000  0.000000  0.000000\n",
              "U-ORG          106   0.777778  0.132075  0.225806\n",
              "U-PERSON        86   0.682927  0.651163  0.666667\n",
              "U-PRODUCT       12   0.000000  0.000000  0.000000\n",
              "U-TITLE        196   0.868132  0.403061  0.550523\n",
              "micro        76800   0.980674  0.978802  0.978274"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 3s 31ms/step\n",
            "3.658239526748657\n",
            "Train on 200 samples, validate on 100 samples\n",
            "Epoch 1/20\n",
            "200/200 [==============================] - 27s 134ms/step - loss: 0.6825 - val_loss: 0.1457\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.1352 - val_loss: 0.1222\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.1119 - val_loss: 0.0962\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0911 - val_loss: 0.0818\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0770 - val_loss: 0.0755\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0654 - val_loss: 0.0608\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0579 - val_loss: 0.0625\n",
            "saving\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in long_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Support</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>B-DATE</th>\n",
              "      <td>145</td>\n",
              "      <td>0.737179</td>\n",
              "      <td>0.793103</td>\n",
              "      <td>0.764120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-GPE</th>\n",
              "      <td>6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-LAW</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-MONEY</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-NORP</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-ORG</th>\n",
              "      <td>381</td>\n",
              "      <td>0.765487</td>\n",
              "      <td>0.454068</td>\n",
              "      <td>0.570016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-PERCENT</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-PERSON</th>\n",
              "      <td>43</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>0.558140</td>\n",
              "      <td>0.705882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-PRODUCT</th>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-TITLE</th>\n",
              "      <td>136</td>\n",
              "      <td>0.917526</td>\n",
              "      <td>0.654412</td>\n",
              "      <td>0.763948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-DATE</th>\n",
              "      <td>118</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>0.389831</td>\n",
              "      <td>0.554217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-GPE</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-LAW</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-MONEY</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-ORG</th>\n",
              "      <td>590</td>\n",
              "      <td>0.924419</td>\n",
              "      <td>0.269492</td>\n",
              "      <td>0.417323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-PERSON</th>\n",
              "      <td>34</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.705882</td>\n",
              "      <td>0.827586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-PRODUCT</th>\n",
              "      <td>11</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-TITLE</th>\n",
              "      <td>108</td>\n",
              "      <td>0.393443</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.494845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-DATE</th>\n",
              "      <td>145</td>\n",
              "      <td>0.744048</td>\n",
              "      <td>0.862069</td>\n",
              "      <td>0.798722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-GPE</th>\n",
              "      <td>6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-LAW</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-MONEY</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-NORP</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-ORG</th>\n",
              "      <td>381</td>\n",
              "      <td>0.820189</td>\n",
              "      <td>0.682415</td>\n",
              "      <td>0.744986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-PERCENT</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-PERSON</th>\n",
              "      <td>43</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.116279</td>\n",
              "      <td>0.204082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-PRODUCT</th>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-TITLE</th>\n",
              "      <td>136</td>\n",
              "      <td>0.754545</td>\n",
              "      <td>0.610294</td>\n",
              "      <td>0.674797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>O</th>\n",
              "      <td>73965</td>\n",
              "      <td>0.986906</td>\n",
              "      <td>0.999608</td>\n",
              "      <td>0.993216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-CARDINAL</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-DATE</th>\n",
              "      <td>96</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.427083</td>\n",
              "      <td>0.598540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-GPE</th>\n",
              "      <td>19</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-LOC</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-NORP</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-ORDINAL</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-ORG</th>\n",
              "      <td>106</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>0.245283</td>\n",
              "      <td>0.371429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-PERSON</th>\n",
              "      <td>86</td>\n",
              "      <td>0.638298</td>\n",
              "      <td>0.697674</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-PRODUCT</th>\n",
              "      <td>12</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-TITLE</th>\n",
              "      <td>196</td>\n",
              "      <td>0.736264</td>\n",
              "      <td>0.683673</td>\n",
              "      <td>0.708995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>micro</th>\n",
              "      <td>76800</td>\n",
              "      <td>0.979572</td>\n",
              "      <td>0.981406</td>\n",
              "      <td>0.978021</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Support  Precision    Recall        F1\n",
              "Label                                            \n",
              "B-DATE         145   0.737179  0.793103  0.764120\n",
              "B-GPE            6   0.000000  0.000000  0.000000\n",
              "B-LAW            2   0.000000  0.000000  0.000000\n",
              "B-MONEY          3   0.000000  0.000000  0.000000\n",
              "B-NORP           0   0.000000       NaN       NaN\n",
              "B-ORG          381   0.765487  0.454068  0.570016\n",
              "B-PERCENT        0   0.000000       NaN       NaN\n",
              "B-PERSON        43   0.960000  0.558140  0.705882\n",
              "B-PRODUCT        7   0.000000  0.000000  0.000000\n",
              "B-TITLE        136   0.917526  0.654412  0.763948\n",
              "I-DATE         118   0.958333  0.389831  0.554217\n",
              "I-GPE            3   0.000000  0.000000  0.000000\n",
              "I-LAW            1   0.000000  0.000000  0.000000\n",
              "I-MONEY          2   0.000000  0.000000  0.000000\n",
              "I-ORG          590   0.924419  0.269492  0.417323\n",
              "I-PERSON        34   1.000000  0.705882  0.827586\n",
              "I-PRODUCT       11   0.000000  0.000000  0.000000\n",
              "I-TITLE        108   0.393443  0.666667  0.494845\n",
              "L-DATE         145   0.744048  0.862069  0.798722\n",
              "L-GPE            6   0.000000  0.000000  0.000000\n",
              "L-LAW            2   0.000000  0.000000  0.000000\n",
              "L-MONEY          3   0.000000  0.000000  0.000000\n",
              "L-NORP           0   0.000000       NaN       NaN\n",
              "L-ORG          381   0.820189  0.682415  0.744986\n",
              "L-PERCENT        0   0.000000       NaN       NaN\n",
              "L-PERSON        43   0.833333  0.116279  0.204082\n",
              "L-PRODUCT        7   0.000000  0.000000  0.000000\n",
              "L-TITLE        136   0.754545  0.610294  0.674797\n",
              "O            73965   0.986906  0.999608  0.993216\n",
              "U-CARDINAL       2   0.000000  0.000000  0.000000\n",
              "U-DATE          96   1.000000  0.427083  0.598540\n",
              "U-GPE           19   0.000000  0.000000  0.000000\n",
              "U-LOC            0   0.000000       NaN       NaN\n",
              "U-NORP           3   0.000000  0.000000  0.000000\n",
              "U-ORDINAL        2   0.000000  0.000000  0.000000\n",
              "U-ORG          106   0.764706  0.245283  0.371429\n",
              "U-PERSON        86   0.638298  0.697674  0.666667\n",
              "U-PRODUCT       12   0.000000  0.000000  0.000000\n",
              "U-TITLE        196   0.736264  0.683673  0.708995\n",
              "micro        76800   0.979572  0.981406  0.978021"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 4s 37ms/step\n",
            "3.679733295440674\n",
            "Train on 300 samples, validate on 100 samples\n",
            "Epoch 1/20\n",
            "300/300 [==============================] - 38s 127ms/step - loss: 0.4851 - val_loss: 0.1340\n",
            "Epoch 2/20\n",
            "300/300 [==============================] - 34s 115ms/step - loss: 0.1182 - val_loss: 0.0947\n",
            "Epoch 3/20\n",
            "300/300 [==============================] - 34s 114ms/step - loss: 0.0875 - val_loss: 0.0710\n",
            "Epoch 4/20\n",
            "300/300 [==============================] - 34s 114ms/step - loss: 0.0675 - val_loss: 0.0568\n",
            "Epoch 5/20\n",
            "300/300 [==============================] - 34s 113ms/step - loss: 0.0573 - val_loss: 0.0499\n",
            "Epoch 6/20\n",
            "300/300 [==============================] - 34s 115ms/step - loss: 0.0459 - val_loss: 0.0423\n",
            "Epoch 7/20\n",
            "300/300 [==============================] - 34s 113ms/step - loss: 0.0401 - val_loss: 0.0382\n",
            "Epoch 8/20\n",
            "300/300 [==============================] - 34s 113ms/step - loss: 0.0361 - val_loss: 0.0349\n",
            "Epoch 9/20\n",
            "300/300 [==============================] - 34s 112ms/step - loss: 0.0313 - val_loss: 0.0339\n",
            "Epoch 10/20\n",
            "300/300 [==============================] - 34s 113ms/step - loss: 0.0279 - val_loss: 0.0320\n",
            "Epoch 11/20\n",
            "300/300 [==============================] - 34s 114ms/step - loss: 0.0259 - val_loss: 0.0315\n",
            "Epoch 12/20\n",
            "300/300 [==============================] - 34s 113ms/step - loss: 0.0250 - val_loss: 0.0293\n",
            "Epoch 13/20\n",
            "300/300 [==============================] - 34s 113ms/step - loss: 0.0214 - val_loss: 0.0313\n",
            "saving\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in long_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Support</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>B-DATE</th>\n",
              "      <td>145</td>\n",
              "      <td>0.952055</td>\n",
              "      <td>0.958621</td>\n",
              "      <td>0.955326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-GPE</th>\n",
              "      <td>6</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-LAW</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-MONEY</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-NORP</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-ORG</th>\n",
              "      <td>381</td>\n",
              "      <td>0.811414</td>\n",
              "      <td>0.858268</td>\n",
              "      <td>0.834184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-PERCENT</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-PERSON</th>\n",
              "      <td>43</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>0.860465</td>\n",
              "      <td>0.913580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-PRODUCT</th>\n",
              "      <td>7</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-TITLE</th>\n",
              "      <td>136</td>\n",
              "      <td>0.834532</td>\n",
              "      <td>0.852941</td>\n",
              "      <td>0.843636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-DATE</th>\n",
              "      <td>118</td>\n",
              "      <td>0.914062</td>\n",
              "      <td>0.991525</td>\n",
              "      <td>0.951220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-GPE</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-LAW</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-MONEY</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-ORG</th>\n",
              "      <td>590</td>\n",
              "      <td>0.932203</td>\n",
              "      <td>0.652542</td>\n",
              "      <td>0.767697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-PERSON</th>\n",
              "      <td>34</td>\n",
              "      <td>0.931034</td>\n",
              "      <td>0.794118</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-PRODUCT</th>\n",
              "      <td>11</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-TITLE</th>\n",
              "      <td>108</td>\n",
              "      <td>0.846939</td>\n",
              "      <td>0.768519</td>\n",
              "      <td>0.805825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-DATE</th>\n",
              "      <td>145</td>\n",
              "      <td>0.945946</td>\n",
              "      <td>0.965517</td>\n",
              "      <td>0.955631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-GPE</th>\n",
              "      <td>6</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-LAW</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-MONEY</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-NORP</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-ORG</th>\n",
              "      <td>381</td>\n",
              "      <td>0.840686</td>\n",
              "      <td>0.900262</td>\n",
              "      <td>0.869455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-PERCENT</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-PERSON</th>\n",
              "      <td>43</td>\n",
              "      <td>0.894737</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.839506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-PRODUCT</th>\n",
              "      <td>7</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L-TITLE</th>\n",
              "      <td>136</td>\n",
              "      <td>0.790850</td>\n",
              "      <td>0.889706</td>\n",
              "      <td>0.837370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>O</th>\n",
              "      <td>73965</td>\n",
              "      <td>0.996682</td>\n",
              "      <td>0.999067</td>\n",
              "      <td>0.997873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-CARDINAL</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-DATE</th>\n",
              "      <td>96</td>\n",
              "      <td>0.965116</td>\n",
              "      <td>0.864583</td>\n",
              "      <td>0.912088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-GPE</th>\n",
              "      <td>19</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.315789</td>\n",
              "      <td>0.461538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-LOC</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-NORP</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-ORDINAL</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-ORG</th>\n",
              "      <td>106</td>\n",
              "      <td>0.707317</td>\n",
              "      <td>0.820755</td>\n",
              "      <td>0.759825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-PERSON</th>\n",
              "      <td>86</td>\n",
              "      <td>0.948052</td>\n",
              "      <td>0.848837</td>\n",
              "      <td>0.895706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-PRODUCT</th>\n",
              "      <td>12</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>U-TITLE</th>\n",
              "      <td>196</td>\n",
              "      <td>0.876847</td>\n",
              "      <td>0.908163</td>\n",
              "      <td>0.892231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>micro</th>\n",
              "      <td>76800</td>\n",
              "      <td>0.991888</td>\n",
              "      <td>0.992292</td>\n",
              "      <td>0.991746</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Support  Precision    Recall        F1\n",
              "Label                                            \n",
              "B-DATE         145   0.952055  0.958621  0.955326\n",
              "B-GPE            6   1.000000  0.166667  0.285714\n",
              "B-LAW            2   0.000000  0.000000  0.000000\n",
              "B-MONEY          3   0.000000  0.000000  0.000000\n",
              "B-NORP           0   0.000000       NaN       NaN\n",
              "B-ORG          381   0.811414  0.858268  0.834184\n",
              "B-PERCENT        0   0.000000       NaN       NaN\n",
              "B-PERSON        43   0.973684  0.860465  0.913580\n",
              "B-PRODUCT        7   1.000000  0.142857  0.250000\n",
              "B-TITLE        136   0.834532  0.852941  0.843636\n",
              "I-DATE         118   0.914062  0.991525  0.951220\n",
              "I-GPE            3   0.000000  0.000000  0.000000\n",
              "I-LAW            1   0.000000  0.000000  0.000000\n",
              "I-MONEY          2   0.000000  0.000000  0.000000\n",
              "I-ORG          590   0.932203  0.652542  0.767697\n",
              "I-PERSON        34   0.931034  0.794118  0.857143\n",
              "I-PRODUCT       11   0.000000  0.000000  0.000000\n",
              "I-TITLE        108   0.846939  0.768519  0.805825\n",
              "L-DATE         145   0.945946  0.965517  0.955631\n",
              "L-GPE            6   0.333333  0.166667  0.222222\n",
              "L-LAW            2   0.000000  0.000000  0.000000\n",
              "L-MONEY          3   0.000000  0.000000  0.000000\n",
              "L-NORP           0   0.000000       NaN       NaN\n",
              "L-ORG          381   0.840686  0.900262  0.869455\n",
              "L-PERCENT        0   0.000000       NaN       NaN\n",
              "L-PERSON        43   0.894737  0.790698  0.839506\n",
              "L-PRODUCT        7   1.000000  0.142857  0.250000\n",
              "L-TITLE        136   0.790850  0.889706  0.837370\n",
              "O            73965   0.996682  0.999067  0.997873\n",
              "U-CARDINAL       2   0.000000  0.000000  0.000000\n",
              "U-DATE          96   0.965116  0.864583  0.912088\n",
              "U-GPE           19   0.857143  0.315789  0.461538\n",
              "U-LOC            0   0.000000       NaN       NaN\n",
              "U-NORP           3   0.000000  0.000000  0.000000\n",
              "U-ORDINAL        2   0.000000  0.000000  0.000000\n",
              "U-ORG          106   0.707317  0.820755  0.759825\n",
              "U-PERSON        86   0.948052  0.848837  0.895706\n",
              "U-PRODUCT       12   0.923077  1.000000  0.960000\n",
              "U-TITLE        196   0.876847  0.908163  0.892231\n",
              "micro        76800   0.991888  0.992292  0.991746"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}