{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EDA",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBuRi4rn-AvT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "24db57da-77b8-48e4-efc4-30577c9ad9ae"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import sys\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import ast\n",
        "from IPython.display import display\n",
        "\n",
        "from shutil import copyfile\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "csv.field_size_limit(sys.maxsize)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9223372036854775807"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsGBhC36-Gz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### File configurations\n",
        "drive_dir = \"/content/drive/My Drive/W266_Project/\"\n",
        "data_src = os.path.join(drive_dir,\"ontonotes\")\n",
        "embed_src = os.path.join(drive_dir,\"embeddings\")\n",
        "\n",
        "train_file = 'onto.train.ner'\n",
        "embedding_file = \"glove.6B.50d.txt\"\n",
        "\n",
        "### Preprocessing Parameters\n",
        "UNK_WORD = \"<UNK-WORD>\"\n",
        "PAD_WORD = \"<PAD-WORD>\"\n",
        "\n",
        "UNK_CHAR = \"<UNK-CHAR>\"\n",
        "PAD_CHAR = \"<PAD-CHAR>\"\n",
        "\n",
        "# max number of words in a sentence, pad to this length, might throw an error if the sentence is longer\n",
        "SENTENCE_WIDTH = 256\n",
        "# max number of characters in a word, pad to this length, will truncate if word is too long\n",
        "WORD_WIDTH = 52\n",
        "# symbols to map padding to\n",
        "CHAR_PAD_SYMBOL = PAD_CHAR\n",
        "LABEL_PAD_SYMBOL = 'O'\n",
        "CASE_PAD_SYMBOL = 'other'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtSo53DxDsuD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f389caf3-d9c4-4053-aa3d-ce78f91c34a6"
      },
      "source": [
        "for file in os.listdir(os.path.join(drive_dir, 'data')):\n",
        "  print(file)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TEST (1).CSV\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoEfYUhW-TSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z = pd.read_csv(os.path.join(drive_dir, 'data', 'TEST (1).CSV'), sep=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wdG3Vgz-mGn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "1a3b5332-838f-4769-cdfe-f20dc4b6695e"
      },
      "source": [
        "z.label.unique()"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['B-PERSON', 'I-PERSON', 'O', 'B-DATE', 'I-DATE', 'B-TITLE',\n",
              "       'B-ORG', 'I-TITLE', nan, 'I-ORG', 'B-PERCENT', 'I-PERCENT',\n",
              "       'B-GPE', 'I-GPE', 'B-PRODUCT', 'I-PRODUCT', 'B-CARDINAL',\n",
              "       'B-MONEY', 'I-MONEY', 'B-LAW', 'I-LAW', 'B-NORP', 'I-NORP',\n",
              "       ' B-GPE'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbo5YHsjAGe6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20f4a5f7-13ef-4f7d-db73-133b5a39b15a"
      },
      "source": [
        "z.shape"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10935, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoU-zmMxAJey",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "e0c7c65e-4e45-4a4b-972c-77689d8563e2"
      },
      "source": [
        "z.head()"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>company</th>\n",
              "      <th>director</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Jeffrey</td>\n",
              "      <td>AMAZON.COM INC</td>\n",
              "      <td>1.0</td>\n",
              "      <td>B-PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P.</td>\n",
              "      <td>AMAZON.COM INC</td>\n",
              "      <td>1.0</td>\n",
              "      <td>I-PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bezos</td>\n",
              "      <td>AMAZON.COM INC</td>\n",
              "      <td>1.0</td>\n",
              "      <td>I-PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>,</td>\n",
              "      <td>AMAZON.COM INC</td>\n",
              "      <td>1.0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>age</td>\n",
              "      <td>AMAZON.COM INC</td>\n",
              "      <td>1.0</td>\n",
              "      <td>B-DATE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     token         company  director     label\n",
              "0  Jeffrey  AMAZON.COM INC       1.0  B-PERSON\n",
              "1       P.  AMAZON.COM INC       1.0  I-PERSON\n",
              "2    Bezos  AMAZON.COM INC       1.0  I-PERSON\n",
              "3        ,  AMAZON.COM INC       1.0         O\n",
              "4      age  AMAZON.COM INC       1.0    B-DATE"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktlp7t_3_2uE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def checkPrior(blah):\n",
        "  if blah is np.NaN:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "# see if prior row was a newline\n",
        "z['prior'] = z.token.shift(1)\n",
        "# drop empty rows\n",
        "z = z.loc[~z.token.isnull()]\n",
        "z['prior'] = z.prior.apply(checkPrior)\n",
        "z['phrase'] = z.prior.cumsum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQKAn5CCAbrY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "181cbea5-301b-4e93-c750-e03b24388028"
      },
      "source": [
        "z.head()"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>company</th>\n",
              "      <th>director</th>\n",
              "      <th>label</th>\n",
              "      <th>prior</th>\n",
              "      <th>phrase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Jeffrey</td>\n",
              "      <td>AMAZON.COM INC</td>\n",
              "      <td>1.0</td>\n",
              "      <td>B-PERSON</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P.</td>\n",
              "      <td>AMAZON.COM INC</td>\n",
              "      <td>1.0</td>\n",
              "      <td>I-PERSON</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bezos</td>\n",
              "      <td>AMAZON.COM INC</td>\n",
              "      <td>1.0</td>\n",
              "      <td>I-PERSON</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>,</td>\n",
              "      <td>AMAZON.COM INC</td>\n",
              "      <td>1.0</td>\n",
              "      <td>O</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>age</td>\n",
              "      <td>AMAZON.COM INC</td>\n",
              "      <td>1.0</td>\n",
              "      <td>B-DATE</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     token         company  director     label  prior  phrase\n",
              "0  Jeffrey  AMAZON.COM INC       1.0  B-PERSON   True       1\n",
              "1       P.  AMAZON.COM INC       1.0  I-PERSON  False       1\n",
              "2    Bezos  AMAZON.COM INC       1.0  I-PERSON  False       1\n",
              "3        ,  AMAZON.COM INC       1.0         O  False       1\n",
              "4      age  AMAZON.COM INC       1.0    B-DATE  False       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhwEv0DVGlrn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "outputId": "7a8daeb7-97bc-4ca8-8f0e-49118bef1dac"
      },
      "source": [
        "z.groupby('label').agg('count')"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>company</th>\n",
              "      <th>director</th>\n",
              "      <th>prior</th>\n",
              "      <th>phrase</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>B-GPE</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-CARDINAL</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-DATE</th>\n",
              "      <td>336</td>\n",
              "      <td>336</td>\n",
              "      <td>336</td>\n",
              "      <td>336</td>\n",
              "      <td>336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-GPE</th>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-LAW</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-MONEY</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-NORP</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-ORG</th>\n",
              "      <td>671</td>\n",
              "      <td>671</td>\n",
              "      <td>671</td>\n",
              "      <td>671</td>\n",
              "      <td>671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-PERCENT</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-PERSON</th>\n",
              "      <td>211</td>\n",
              "      <td>211</td>\n",
              "      <td>211</td>\n",
              "      <td>211</td>\n",
              "      <td>211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-PRODUCT</th>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-TITLE</th>\n",
              "      <td>511</td>\n",
              "      <td>511</td>\n",
              "      <td>511</td>\n",
              "      <td>511</td>\n",
              "      <td>511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-DATE</th>\n",
              "      <td>430</td>\n",
              "      <td>430</td>\n",
              "      <td>430</td>\n",
              "      <td>430</td>\n",
              "      <td>430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-GPE</th>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-LAW</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-MONEY</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-NORP</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-ORG</th>\n",
              "      <td>1324</td>\n",
              "      <td>1324</td>\n",
              "      <td>1324</td>\n",
              "      <td>1324</td>\n",
              "      <td>1324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-PERCENT</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-PERSON</th>\n",
              "      <td>121</td>\n",
              "      <td>121</td>\n",
              "      <td>121</td>\n",
              "      <td>121</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-PRODUCT</th>\n",
              "      <td>34</td>\n",
              "      <td>34</td>\n",
              "      <td>34</td>\n",
              "      <td>34</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-TITLE</th>\n",
              "      <td>346</td>\n",
              "      <td>346</td>\n",
              "      <td>346</td>\n",
              "      <td>346</td>\n",
              "      <td>346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>O</th>\n",
              "      <td>6455</td>\n",
              "      <td>6455</td>\n",
              "      <td>6455</td>\n",
              "      <td>6455</td>\n",
              "      <td>6455</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            token  company  director  prior  phrase\n",
              "label                                              \n",
              " B-GPE          1        1         1      1       1\n",
              "B-CARDINAL      2        2         2      2       2\n",
              "B-DATE        336      336       336    336     336\n",
              "B-GPE          45       45        45     45      45\n",
              "B-LAW           1        1         1      1       1\n",
              "B-MONEY         1        1         1      1       1\n",
              "B-NORP          1        1         1      1       1\n",
              "B-ORG         671      671       671    671     671\n",
              "B-PERCENT       2        2         2      2       2\n",
              "B-PERSON      211      211       211    211     211\n",
              "B-PRODUCT      16       16        16     16      16\n",
              "B-TITLE       511      511       511    511     511\n",
              "I-DATE        430      430       430    430     430\n",
              "I-GPE          20       20        20     20      20\n",
              "I-LAW           2        2         2      2       2\n",
              "I-MONEY         1        1         1      1       1\n",
              "I-NORP          1        1         1      1       1\n",
              "I-ORG        1324     1324      1324   1324    1324\n",
              "I-PERCENT       2        2         2      2       2\n",
              "I-PERSON      121      121       121    121     121\n",
              "I-PRODUCT      34       34        34     34      34\n",
              "I-TITLE       346      346       346    346     346\n",
              "O            6455     6455      6455   6455    6455"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKlxsDb4H2_P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0320237a-2f55-4bd7-c373-efd551c26643"
      },
      "source": [
        "len(z[z.label == 'B-TITLE'])"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "511"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_-Yaw78BrO3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "71a07d82-2e19-4d2e-cb1b-9b39a5f7bdcf"
      },
      "source": [
        "print(f\"Number of directors: {len(z.director.unique())}\")\n",
        "print(f\"Number of companies: {len(z.company.unique())}\")\n",
        "print(f\"Number of sentences: {z.phrase.max()}\")\n",
        "print(f\"Number of unique tokens: {len(z.token.unique())}\")\n",
        "print(f\"Average number of tokens per sentence: {z.groupby('phrase').size().mean()}\")\n",
        "print(f\"Instances of ORG label:{len(z[z.label == 'B-ORG'])}\")\n",
        "print(f\"Instances of TITLE label: {len(z[z.label == 'B-TITLE'])}\")"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of directors: 50\n",
            "Number of companies: 11\n",
            "Number of sentences: 400\n",
            "Number of unique tokens: 1705\n",
            "Average number of tokens per sentence: 26.34\n",
            "Instances of ORG label:671\n",
            "Instances of TITLE label: 511\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZ5QrP7E_4Kx",
        "colab_type": "text"
      },
      "source": [
        "# Validate that file transforms into format for model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjTfVE6g-57d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# consider using tf.nn.embedding_lookup instead\n",
        "# or maybe nltk.tokenize\n",
        "\n",
        "\n",
        "def get_casing_ix(word):\n",
        "  '''\n",
        "  determines the casing of the word\n",
        "  \n",
        "  returns casing_ix\n",
        "  '''\n",
        "  if word.istitle():\n",
        "    return case_to_ix['title']\n",
        "  elif word.islower():\n",
        "    return case_to_ix['lower']\n",
        "  elif word.isupper():\n",
        "    return case_to_ix['upper']\n",
        "  elif word.isnumeric():\n",
        "    return case_to_ix['numeric']\n",
        "  return case_to_ix['other']\n",
        "\n",
        "def get_word_ix(word):\n",
        "  '''\n",
        "  takes w and returns the index of the word embedding\n",
        "  out of vocabulary terms return the UNK_WORD and the character embeddings\n",
        "  \n",
        "  returns word_ix\n",
        "  '''\n",
        "  w = word.lower()\n",
        "  w_ix = word_to_ix.get(w)\n",
        "  if w_ix is not None:\n",
        "    return w_ix\n",
        "  return word_to_ix[UNK_WORD]\n",
        "\n",
        "def get_char_ix(char):\n",
        "  char_ix = char_to_ix.get(char)\n",
        "  if char_ix is not None:\n",
        "    return char_ix\n",
        "  return char_to_ix[UNK_CHAR]\n",
        "  \n",
        "def create_character_embeddings(words_df):\n",
        "  '''\n",
        "  Optional function to create pre-trained character embeddings from averaged word embeddings.  In the model we generate them from a uniform random distribution and train.\n",
        "  '''\n",
        "  characters = {}\n",
        "  for i, word_vec in enumerate(words_df.reset_index().values):\n",
        "    for char in word_vec[0]:\n",
        "      if char in characters:\n",
        "        characters[char] = [characters[char][0] + word_vec[1:].astype(float), characters[char][1] + 1]\n",
        "      else:\n",
        "        characters[char] = [word_vec[1:].astype(float), 1]\n",
        "\n",
        "  for key in characters:\n",
        "    characters[key] = np.round(characters[key][0]/characters[key][1],6)\n",
        "    \n",
        "def initialize_word_embeddings(file_name, use_cache=True, debug=True, save_cache=True):\n",
        "  loaded = False\n",
        "  df = None\n",
        "  \n",
        "  if use_cache:\n",
        "    try:\n",
        "      print(\"Attempting to load from cache\")\n",
        "      with pd.HDFStore(embed_store, 'r') as store:\n",
        "        words = store[file_name]\n",
        "      words = pd.read_hdf(embed_store, file_name)\n",
        "      loaded=True\n",
        "      print(\"Loaded successfully\")\n",
        "    except:\n",
        "      print(\"Cache loading failed\")\n",
        "      loaded=False\n",
        "  \n",
        "  if not loaded:\n",
        "    words = pd.read_csv(os.path.join(embed_src, embedding_file), sep=\" \", index_col=0, header=None, quoting=csv.QUOTE_NONE)\n",
        "    # some embeddings come back with word == NaN\n",
        "    words = words[~words.index.isnull()]\n",
        "    # add entries for special tokens\n",
        "    words.loc[UNK_WORD] = [0 for x in words.columns]\n",
        "    words.loc[PAD_WORD] = [0 for x in words.columns]\n",
        "    if save_cache:\n",
        "      with pd.HDFStore(embed_store, 'a') as store:\n",
        "        store[file_name] = words\n",
        "  \n",
        "  word2ix = {word:i for i,word in enumerate(words.index)}\n",
        "  ix2word = {i:word for i,word in enumerate(words.index)}\n",
        "  words = words.to_numpy().astype(float)\n",
        "  \n",
        "  return words, word2ix, ix2word\n",
        "\n",
        "def initialize_character_embeddings(vocab=string.printable):\n",
        "  characters = [x for x in string.printable]\n",
        "  characters += [UNK_CHAR, PAD_CHAR]\n",
        "  char2ix = {ch:i for i, ch in enumerate(characters)}\n",
        "  ix2char = {i:ch for i, ch in enumerate(characters)}\n",
        "  \n",
        "  return characters, char2ix, ix2char\n",
        "\n",
        "def initialize_case_embeddings(vocab=['upper','lower','title','numeric','other']):\n",
        "  case2ix = {case:i for i, case in enumerate(vocab)}\n",
        "  ix2case = {}\n",
        "  cases = []\n",
        "  for k,v in case2ix.items():\n",
        "    this_case = np.zeros(len(case2ix))\n",
        "    this_case[v] = 1\n",
        "    cases.append(this_case)\n",
        "    ix2case[v] = k\n",
        "  cases = np.array(cases)\n",
        "  \n",
        "  return cases, case2ix, ix2case\n",
        "\n",
        "  \n",
        "def initialize_labels(file_name):\n",
        "  data = pd.read_csv(os.path.join(data_src, file_name), sep=\"\\t\",  quoting=csv.QUOTE_NONE, header=None, skip_blank_lines=False, engine='python', names =['token', 'pos', 'tree', 'BIO'])\n",
        "  data.dropna(subset=['BIO'], inplace=True)\n",
        "  label_list = data.BIO.unique()\n",
        "  label2ix = {label:i for i, label in enumerate(label_list)}\n",
        "  ix2label = {i:label for i, label in enumerate(label_list)}\n",
        "  return label_list, label2ix, ix2label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wR592KT-7jJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load embeddings and format\n",
        "words, word_to_ix, ix_to_word = initialize_word_embeddings(embedding_file, use_cache=False, save_cache=False)\n",
        "characters, char_to_ix, ix_to_char = initialize_character_embeddings()\n",
        "cases, case_to_ix, ix_to_case = initialize_case_embeddings()\n",
        "labels, label_to_ix, ix_to_label = initialize_labels(train_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-MApt-q_K8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def checkPrior(blah):\n",
        "  if blah is None:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "  \n",
        "def phrase2char(w_vec):\n",
        "  '''\n",
        "  This function transforms a sequence of words in index format to a 2d array of character indexes\n",
        "  \n",
        "  w_vec - an iterable of word indexes\n",
        "  \n",
        "  returns np.ndarray of size (len(w_vec), WORD_WIDTH)\n",
        "  '''\n",
        "  phrase_vector = []\n",
        "  for w_ix in w_vec:\n",
        "    char_vector = []\n",
        "    if w_ix not in (word_to_ix[PAD_WORD],word_to_ix[UNK_WORD]):\n",
        "      for char in ix_to_word[w_ix]:\n",
        "        char_vector.append(get_char_ix(char))\n",
        "    phrase_vector.append(np.array(char_vector))\n",
        "  return pad_sequences(phrase_vector, value=char_to_ix[PAD_CHAR], maxlen=WORD_WIDTH, padding='post')\n",
        "\n",
        "def pad_truncate(x,width,pad_token):\n",
        "  if(len(x) > width):\n",
        "    print(f\"Truncating input: {[ix_to_word[ix] for ix in x]}\")\n",
        "    x = x[:256]\n",
        "  return np.pad(x,pad_width=(0,width-len(x)), mode='constant', constant_values=pad_token)\n",
        "\n",
        "def verbosity(str, verbose):\n",
        "  if verbose:\n",
        "    print(str)\n",
        "\n",
        "def preprocess_data(file_name, use_cache=True, debug=True):\n",
        "  '''\n",
        "  Prepares data for model.  It can be used for both training and test data.\n",
        "  \n",
        "  returns pd.DataFrame\n",
        "  '''\n",
        "  clean_name = os.path.join(cache_dir, file_name.replace(\".\", \"_\"))\n",
        "  loaded = False\n",
        "  phrase_vectors = None\n",
        "      \n",
        "  if use_cache and os.path.exists(clean_name+\"word.npy\"):\n",
        "    verbosity(\"Attempting to load from cache\", debug)\n",
        "    try:\n",
        "      word_vectors = np.load(clean_name+\"word.npy\", allow_pickle=True)\n",
        "      char_vectors = np.load(clean_name+\"char.npy\", allow_pickle=True)\n",
        "      case_vectors = np.load(clean_name+\"case.npy\", allow_pickle=True)\n",
        "      label_vectors = np.load(clean_name+\"label.npy\", allow_pickle=True)\n",
        "      phrase_vectors = [word_vectors, char_vectors, case_vectors, label_vectors]\n",
        "      loaded = True\n",
        "      verbosity(\"Loaded successfully\", debug)\n",
        "    except:\n",
        "      verbosity(\"Loading failed\",debug)\n",
        "      loaded = False\n",
        "  \n",
        "  if not loaded:\n",
        "    verbosity(f\"Loading raw data file to process labels: {file_name}\", debug)\n",
        "    checkpoint = time.time()  \n",
        "    data = pd.read_csv(os.path.join(data_src, file_name), sep=\"\\t\",  quoting=csv.QUOTE_NONE, header=None, skip_blank_lines=False, engine='python', names =['token', 'pos', 'tree', 'BIO'])\n",
        "    verbosity(f\"Parsed data loaded: {time.time()-checkpoint} s\", debug)\n",
        "\n",
        "    # see if prior row was a newline\n",
        "    data['prior'] = data.token.shift(1)\n",
        "    # drop empty rows\n",
        "    data = data.loc[~data.token.isnull()]\n",
        "    data.prior = data.prior.apply(checkPrior)\n",
        "    data['phrase'] = data.prior.cumsum()\n",
        "        \n",
        "    verbosity(\"Processing data into phrase vectors\", debug)\n",
        "    verbosity(\"Step 1: Translating to indexes\", debug)\n",
        "    checkpoint = time.time()\n",
        "    data['word_ix'] = data.token.apply(get_word_ix)\n",
        "    data['case_ix'] = data.token.apply(get_casing_ix)\n",
        "    data['label_ix'] = data.BIO.apply(lambda x: label_to_ix[x])\n",
        "    verbosity(f\"Step 1: Translated to indexes complete: {time.time()-checkpoint} s\", debug)\n",
        "\n",
        "    verbosity(\"Step 2: Creating phrase vectors\", debug)\n",
        "    verbosity(\"Step 2a: Aggregating phrases\", debug)\n",
        "    checkpoint = time.time()\n",
        "    phrase_vectors = data.groupby('phrase').agg({'word_ix': list, 'case_ix': list, 'label_ix': list})\n",
        "    verbosity(f\"Step 2a: {time.time()-checkpoint} s\", debug)\n",
        "    \n",
        "    verbosity(\"Step 2b: Padding word vectors\", debug)\n",
        "    checkpoint = time.time()\n",
        "    phrase_vectors['word_vector'] = phrase_vectors.word_ix.apply(lambda x: pad_truncate(x, SENTENCE_WIDTH, word_to_ix[PAD_WORD]))\n",
        "    verbosity(f\"Step 2b: {time.time()-checkpoint} s\", debug)\n",
        "    \n",
        "    verbosity(\"Step 2c: Creating and padding character vectors\", debug)\n",
        "    checkpoint = time.time()\n",
        "    phrase_vectors['char_vector'] = phrase_vectors.word_vector.apply(lambda x: phrase2char(x))\n",
        "    verbosity(f\"Step 2c: {time.time()-checkpoint} s\", debug)\n",
        "    \n",
        "    verbosity(f\"Step 2d: Padding case vectors\", debug)\n",
        "    checkpoint = time.time()\n",
        "    phrase_vectors['case_vector'] = phrase_vectors.case_ix.apply(lambda x: pad_truncate(x, SENTENCE_WIDTH, case_to_ix[CASE_PAD_SYMBOL]))\n",
        "    verbosity(f\"Step 2d: {time.time()-checkpoint}\", debug)\n",
        "    \n",
        "    verbosity(\"Step 2e: Padding label vectors\", debug)\n",
        "    checkpoint = time.time()\n",
        "    phrase_vectors['label_vector'] = phrase_vectors.label_ix.apply(lambda x: np.expand_dims(pad_truncate(x, SENTENCE_WIDTH, label_to_ix[LABEL_PAD_SYMBOL]), -1))\n",
        "    verbosity(f\"Step 2e: {time.time()-checkpoint} s\", debug)\n",
        "    \n",
        "    verbosity(\"Saving data to disk\", debug)\n",
        "    checkpoint = time.time()\n",
        "    phrase_vectors.drop(columns=['word_ix', 'case_ix', 'label_ix'], inplace=True)\n",
        "    phrase_vectors = phrase_vectors.to_numpy()\n",
        "    phrase_vectors = [np.stack(phrase_vectors[:,0]), np.stack(phrase_vectors[:,1]), np.stack(phrase_vectors[:,2]), np.stack(phrase_vectors[:,3])]\n",
        "    \n",
        "    # saving in multi parts because training data causes a memory error\n",
        "    np.save(clean_name+'word', phrase_vectors[0], allow_pickle=True)\n",
        "    np.save(clean_name+'char', phrase_vectors[1], allow_pickle=True)\n",
        "    np.save(clean_name+'case', phrase_vectors[2], allow_pickle=True)\n",
        "    np.save(clean_name+'label', phrase_vectors[3], allow_pickle=True)\n",
        "\n",
        "    verbosity(f\"Saved to disk: {time.time()-checkpoint} s\", debug)\n",
        "  \n",
        "  return phrase_vectors"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}