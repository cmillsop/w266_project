{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "to_BILOU.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwupMwKTpD-r",
        "colab_type": "code",
        "outputId": "b4874371-60a5-44a3-9a42-6741b77f9b85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from typing import Callable, List, Set, Tuple, TypeVar, Optional\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "\n",
        "from google.colab import drive\n",
        "import gzip\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "__dir__ = \"/content/drive/My Drive/W266_Project/\"\n",
        "\n",
        "test_file = os.path.join(__dir__, 'data/onto.test.ner')\n",
        "dev_file = os.path.join(__dir__, 'data/onto.development.ner')\n",
        "train_file = os.path.join(__dir__, 'data/onto.train.ner')\n",
        "domain_file = os.path.join(__dir__, 'data/bios-tagged-final-flat.csv')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOiIEjQlppgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InvalidTagSequence(Exception):\n",
        "    def __init__(self, tag_sequence=None):\n",
        "        super().__init__()\n",
        "        self.tag_sequence = tag_sequence\n",
        "\n",
        "    def __str__(self):\n",
        "        return ' '.join(self.tag_sequence)\n",
        "\n",
        "def to_bioul(tag_sequence: List[str], encoding: str = \"IOB1\") -> List[str]:\n",
        "    \"\"\"\n",
        "    Given a tag sequence encoded with IOB1 labels, recode to BIOUL.\n",
        "    In the IOB1 scheme, I is a token inside a span, O is a token outside\n",
        "    a span and B is the beginning of span immediately following another\n",
        "    span of the same type.\n",
        "    In the BIO scheme, I is a token inside a span, O is a token outside\n",
        "    a span and B is the beginning of a span.\n",
        "    Parameters\n",
        "    ----------\n",
        "    tag_sequence : ``List[str]``, required.\n",
        "        The tag sequence encoded in IOB1, e.g. [\"I-PER\", \"I-PER\", \"O\"].\n",
        "    encoding : `str`, optional, (default = ``IOB1``).\n",
        "        The encoding type to convert from. Must be either \"IOB1\" or \"BIO\".\n",
        "    Returns\n",
        "    -------\n",
        "    bioul_sequence: ``List[str]``\n",
        "        The tag sequence encoded in IOB1, e.g. [\"B-PER\", \"L-PER\", \"O\"].\n",
        "    \"\"\"\n",
        "\n",
        "    if not encoding in {\"IOB1\", \"BIO\"}:\n",
        "        raise ConfigurationError(f\"Invalid encoding {encoding} passed to 'to_bioul'.\")\n",
        "    # pylint: disable=len-as-condition\n",
        "\n",
        "    def replace_label(full_label, new_label):\n",
        "        # example: full_label = 'I-PER', new_label = 'U', returns 'U-PER'\n",
        "        parts = list(full_label.partition('-'))\n",
        "        parts[0] = new_label\n",
        "        return ''.join(parts)\n",
        "\n",
        "    def pop_replace_append(in_stack, out_stack, new_label):\n",
        "        # pop the last element from in_stack, replace the label, append\n",
        "        # to out_stack\n",
        "        tag = in_stack.pop()\n",
        "        new_tag = replace_label(tag, new_label)\n",
        "        out_stack.append(new_tag)\n",
        "\n",
        "    def process_stack(stack, out_stack):\n",
        "        # process a stack of labels, add them to out_stack\n",
        "        if len(stack) == 1:\n",
        "            # just a U token\n",
        "            pop_replace_append(stack, out_stack, 'U')\n",
        "        else:\n",
        "            # need to code as BIL\n",
        "            recoded_stack = []\n",
        "            pop_replace_append(stack, recoded_stack, 'L')\n",
        "            while len(stack) >= 2:\n",
        "                pop_replace_append(stack, recoded_stack, 'I')\n",
        "            pop_replace_append(stack, recoded_stack, 'B')\n",
        "            recoded_stack.reverse()\n",
        "            out_stack.extend(recoded_stack)\n",
        "\n",
        "\n",
        "    # Process the tag_sequence one tag at a time, adding spans to a stack,\n",
        "    # then recode them.\n",
        "    bioul_sequence = []\n",
        "    stack: List[str] = []\n",
        "\n",
        "    for label in tag_sequence:\n",
        "        # need to make a dict like\n",
        "        # token = {'token': 'Matt', \"labels\": {'conll2003': \"B-PER\"}\n",
        "        #                   'gold': 'I-PER'}\n",
        "        # where 'gold' is the raw value from the CoNLL data set\n",
        "\n",
        "        if label == 'O' and len(stack) == 0:\n",
        "            bioul_sequence.append(label)\n",
        "        elif label == 'O' and len(stack) > 0:\n",
        "            # need to process the entries on the stack plus this one\n",
        "            process_stack(stack, bioul_sequence)\n",
        "            bioul_sequence.append(label)\n",
        "        elif label[0] == 'I':\n",
        "            # check if the previous type is the same as this one\n",
        "            # if it is then append to stack\n",
        "            # otherwise this start a new entity if the type\n",
        "            # is different\n",
        "            if len(stack) == 0:\n",
        "                if encoding == \"BIO\":\n",
        "                    raise InvalidTagSequence(tag_sequence)\n",
        "                stack.append(label)\n",
        "            else:\n",
        "                # check if the previous type is the same as this one\n",
        "                this_type = label.partition('-')[2]\n",
        "                prev_type = stack[-1].partition('-')[2]\n",
        "                if this_type == prev_type:\n",
        "                    stack.append(label)\n",
        "                else:\n",
        "                    if encoding == \"BIO\":\n",
        "                        raise InvalidTagSequence(tag_sequence)\n",
        "                    # a new entity\n",
        "                    process_stack(stack, bioul_sequence)\n",
        "                    stack.append(label)\n",
        "        elif label[0] == 'B':\n",
        "            if len(stack) > 0:\n",
        "                process_stack(stack, bioul_sequence)\n",
        "            stack.append(label)\n",
        "        else:\n",
        "            raise InvalidTagSequence(tag_sequence)\n",
        "\n",
        "    # process the stack\n",
        "    if len(stack) > 0:\n",
        "        process_stack(stack, bioul_sequence)\n",
        "\n",
        "    return bioul_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdKfR6hZpPkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_onto_data_vectors(src_file):\n",
        "  X,y = [], []\n",
        "  sentence = []\n",
        "  ner_sent = []\n",
        "  has_header = False\n",
        "\n",
        "  with open(src_file, 'r') as f:\n",
        "      for line in f.readlines():\n",
        "          if re.search('^token.*label$', line):\n",
        "              # this is the domain file, it has headers\n",
        "              continue\n",
        "          elif not re.search('^\\s+$', line):\n",
        "              #print(line.split('\\t'))\n",
        "              try:\n",
        "                word, *_, ner = line.split('\\t')\n",
        "              except:\n",
        "                print(line)\n",
        "                raise Exception()\n",
        "              #print(ner)\n",
        "              sentence.append(word)\n",
        "              ner_sent.append(ner.rstrip())\n",
        "\n",
        "          elif len(sentence) != 0:\n",
        "              X.append(sentence)\n",
        "              try:\n",
        "                y.append(to_bioul(ner_sent, 'BIO'))\n",
        "              except:\n",
        "                print(sentence)\n",
        "                raise Exception()\n",
        "              sentence = []\n",
        "              ner_sent=[]\n",
        "              continue\n",
        "              \n",
        "  if len(sentence) != 0:\n",
        "    X.append(sentence)\n",
        "    try:\n",
        "        y.append(to_bioul(ner_sent, 'BIO'))\n",
        "    except:\n",
        "        print(sentence)\n",
        "        raise Exception()\n",
        "\n",
        "  return X, y "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzYnlRFtrk50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def df_and_csv(X, y, src_file):\n",
        "  out_name = src_file.replace('.csv', '') + '_bilou.csv'\n",
        "  \n",
        "  pd_bilou = pd.DataFrame([X,y]).T\n",
        "  pd_bilou.columns=['x', 'y']\n",
        "  pd_bilou.head()\n",
        "  pd_bilou.to_csv(out_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHFyhOazu2pl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_dev, y_dev = create_onto_data_vectors(train_file)\n",
        "  \n",
        "df_and_csv(X_dev, y_dev, train_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuVKlcPfzi1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_dev, y_dev = create_onto_data_vectors(dev_file)\n",
        "\n",
        "  \n",
        "df_and_csv(X_dev, y_dev, dev_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkS3HCK6QFHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_dev, y_dev = create_onto_data_vectors(test_file)\n",
        "\n",
        "  \n",
        "df_and_csv(X_dev, y_dev, test_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN6IlErdRbFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_dev, y_dev = create_onto_data_vectors(domain_file)\n",
        "  \n",
        "df_and_csv(X_dev, y_dev, domain_file)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}