{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn-bilou.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfcAugL9v8Jc",
        "colab_type": "code",
        "outputId": "9559a388-c54c-46a6-db07-7a5622a0bfcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import gzip\n",
        "drive.mount('/content/drive/')\n",
        "__dir__ = '/content/drive/My Drive/Colab Notebooks/'\n",
        "DIR_PATH = '/content/drive/My Drive/Colab Notebooks/data/'\n",
        "GZIP_FILE = __dir__ + '/data/GoogleNews-vectors-negative300.bin.gz'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTG7xvF8wOcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBED_DIM = 300\n",
        "MAX_SEQ = 26"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "au3OFnEewTZv",
        "colab_type": "code",
        "outputId": "f92c4bc5-87c4-4bf2-a9cd-26828f1b2cc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "# import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import ast\n",
        "import gensim\n",
        "from smart_open import open\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from collections import Counter, defaultdict, OrderedDict\n",
        "import pandas as pd\n",
        "from itertools import chain\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support,classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras import preprocessing as prepro\n",
        "from keras.layers import TimeDistributed, Dense, Activation, Input, Conv1D, Embedding, GlobalMaxPooling1D, Dropout\n",
        "from keras.layers import concatenate, SimpleRNN, LSTM, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import Adam\n",
        "from keras import metrics\n",
        "\n",
        "from tensorflow.python.tools import inspect_checkpoint as chkp\n",
        "%matplotlib inline\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2asyzj4wXgQ",
        "colab_type": "code",
        "outputId": "a3fdcf8c-351a-4d8e-8262-2b4e8f615b61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "print('This may take a few minutes..')\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format(GZIP_FILE, binary=True)\n",
        "# model.save(word_embeddings)\n",
        "# model.save_word2vec_format(DATA_FILE, binary=False)\n",
        "print('Done!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This may take a few minutes..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bdij6B2qwkQg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_df(data_type):\n",
        "  data_type_dict = {'train' : '/content/drive/My Drive/Colab Notebooks/data/onto.train.ner_bilou.csv',\n",
        "                   'dev' : '/content/drive/My Drive/Colab Notebooks/data/onto.development.ner_bilou.csv',\n",
        "                   'test' : '/content/drive/My Drive/Colab Notebooks/data/onto.test.ner_bilou.csv'}\n",
        "\n",
        "  df = pd.read_csv(data_type_dict[data_type])\n",
        "  \n",
        "  X = df['x'].apply(ast.literal_eval)\n",
        "  y = df['y'].apply(ast.literal_eval)\n",
        "  return X, y\n",
        "  \n",
        "  \n",
        "def split_list_on_break(df):\n",
        "    df = df.fillna('<BREAK>')\n",
        "    list_of_df=[]\n",
        "    for columns in df.columns:\n",
        "        word_seq = []\n",
        "        word_sentences = []\n",
        "        for count, word in enumerate(df):\n",
        "            if word != '<BREAK>':\n",
        "                word_seq.append(str(word))\n",
        "                \n",
        "            else:\n",
        "                word_sentences.append(' '.join(word_seq))\n",
        "                word_seq = []\n",
        "                continue\n",
        "        print(f'Column {columns}, total items - {count}')\n",
        "        print('adding to master list..')\n",
        "        list_of_df.append(word_sentences)\n",
        "        \n",
        "#    print(f'total tokens - {count}')\n",
        "    print('returning list..')\n",
        "    return list_of_df\n",
        "    \n",
        "    \n",
        "# train_dataset = split_list_on_break(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dujz1dWoxLd4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train = get_df('train')\n",
        "X_dev, y_dev = get_df('dev')\n",
        "X_test, y_test = get_df('test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEtMzY1Kz8D4",
        "colab_type": "code",
        "outputId": "90f8e80e-92a1-4a95-bb12-b4ac1f39c947",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "def filter_data_seq(X):\n",
        "  max_length = MAX_SEQ\n",
        "  lengths = [len(x) for x in X]\n",
        "  print(f'Maximum length: {max(lengths)}')\n",
        "  print(f'Minimum length: {min(lengths)}')\n",
        "  print(f'Average length: {sum(lengths)/len(lengths)}')\n",
        "  \n",
        "  short_sentences = [s for s in X if len(s) <= max_length]\n",
        "  print(f'% of short sentences - {100 * len(short_sentences)/len(lengths)}%')\n",
        "\n",
        "filter_data_seq(X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum length: 151\n",
            "Minimum length: 1\n",
            "Average length: 18.83588442334452\n",
            "% of short sentences - 77.30211999672588%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLLTmrw9630Q",
        "colab_type": "code",
        "outputId": "0e93599a-3514-4a85-fa71-349a018d4674",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(len(X_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12217\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxGvK79A790i",
        "colab_type": "code",
        "outputId": "5ea83262-3360-4ff7-885d-807e127e94e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "corpus = [token for sentence in X_train for token in sentence]\n",
        "vocab = ['<PAD>', '<UNK>'] + [token for token, count in Counter(corpus).items() if count >= 2]\n",
        "print(f'Length of vocabulary - {len(vocab)}')\n",
        "token2index = defaultdict(lambda: 1, {token: index for index, token in  enumerate(vocab)})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of vocabulary - 34673\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMHSEzpG8Nf4",
        "colab_type": "code",
        "outputId": "775d5630-aa6e-484a-b206-511d89a1c134",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "embeddings = np.zeros((len(token2index.keys()), EMBED_DIM))\n",
        "no_embed = []\n",
        "print(embeddings.shape)\n",
        "\n",
        "for k, v in token2index.items():\n",
        "   try:\n",
        "      embeddings[v] = model[k]\n",
        "   except:\n",
        "      no_embed.append((k,v))\n",
        "      continue"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(34673, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu2P6uOw8RCf",
        "colab_type": "code",
        "outputId": "ca6f7293-6f46-4cc0-b65e-a5f0afdafda2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(f'% of volcabulary with no embeddings - {100 * len(no_embed)/len(vocab)}%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of volcabulary with no embeddings - 8.268681683154039%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYe14_qa8Z7q",
        "colab_type": "code",
        "outputId": "3dc1a4db-c485-41a8-8d81-c5849d75a164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "label_vocab = ['<PAD>'] + sorted(list(set([label for target_list in y_train for label in target_list])))\n",
        "\n",
        "label2index = {label : index for index, label in enumerate(label_vocab)}\n",
        "index2label = dict([[v,k] for k,v in label2index.items()])\n",
        "print(f'Length of labels - {len(label2index)}')\n",
        "\n",
        "max_label = len(label2index)\n",
        "# print(label2index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of labels - 74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRFAaRZ77hOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEST_FILE = 'bios-tagged-final-flat_bilou.csv'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZDCLBdCJOEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(os.path.join(DIR_PATH, TEST_FILE), header=0, index_col=0,skip_blank_lines=False, engine='python')\n",
        "data = data[data.x.str.len() > 2]\n",
        "\n",
        "data.x = data.x.apply(ast.literal_eval)\n",
        "data.y = data.y.apply(ast.literal_eval)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN_0rKG2JkXh",
        "colab_type": "code",
        "outputId": "17de9348-4825-4940-bdd3-77e1e6601281",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "data.y.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [B-PERSON, I-PERSON, L-PERSON, O, B-DATE, L-DA...\n",
              "1    [O, U-PERSON, O, O, U-TITLE, O, O, O, B-DATE, ...\n",
              "2    [O, U-PERSON, O, O, O, O, O, O, O, U-TITLE, O,...\n",
              "3    [B-PERSON, I-PERSON, L-PERSON, O, B-DATE, L-DA...\n",
              "4    [O, U-PERSON, O, O, O, B-TITLE, I-TITLE, I-TIT...\n",
              "Name: y, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgeVLbME7xi9",
        "colab_type": "code",
        "outputId": "8ad6f3a4-693b-409f-c25d-8b54b4073b9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "X_bios = data.x.tolist()\n",
        "y_bios = data.y.tolist()\n",
        "\n",
        "y_bios_no_title = [['O' if label in ['B-TITLE','U-TITLE','L-TITLE','I-TITLE'] else label for label in seq] for seq in y_bios]\n",
        "print(y_bios_no_title[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['B-PERSON', 'I-PERSON', 'L-PERSON', 'O', 'B-DATE', 'L-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'U-ORG', 'O', 'O', 'O', 'U-ORG', 'O', 'U-DATE', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'L-DATE', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "539OF_eb8EFC",
        "colab_type": "code",
        "outputId": "9a313cfc-7d55-47e4-b061-414700748929",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "print(X_bios[0])\n",
        "print(y_bios[0])\n",
        "print(len(X_bios[500]))\n",
        "print(len(y_bios[500]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Jeffrey', 'P.', 'Bezos', ',', 'age', '55', ',', 'has', 'been', 'Chairman', 'of', 'the', 'Board', 'since', 'founding', 'the', 'Company', 'in', '1994', 'and', 'Chief', 'Executive', 'Officer', 'since', 'May', '1996', '.']\n",
            "['B-PERSON', 'I-PERSON', 'L-PERSON', 'O', 'B-DATE', 'L-DATE', 'O', 'O', 'O', 'U-TITLE', 'O', 'O', 'U-ORG', 'O', 'O', 'O', 'U-ORG', 'O', 'U-DATE', 'O', 'B-TITLE', 'I-TITLE', 'L-TITLE', 'O', 'B-DATE', 'L-DATE', 'O']\n",
            "34\n",
            "34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqsEUxic8duY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_digitized = [[token2index[word] for word in seq] for seq in X_train] \n",
        "y_digitized = [[label2index[label] for label in seq] for seq in y_train]\n",
        "\n",
        "X_dev_digitized = [[token2index[word] for word in seq] for seq in X_dev] \n",
        "y_dev_digitized = [[label2index[label] for label in seq] for seq in y_dev] \n",
        "\n",
        "X_test_digitized = [[token2index[word] for word in seq] for seq in X_test] \n",
        "y_test_digitized = [[label2index[label] for label in seq] for seq in y_test] \n",
        "\n",
        "X_bios_digitized = [[token2index[word] for word in seq] for seq in X_bios] \n",
        "y_bios_digitized = [[label2index[label] for label in seq] for seq in y_bios_no_title] \n",
        "\n",
        "\n",
        "y_digitized  = [to_categorical(target, max_label) for target in y_digitized]\n",
        "y_dev_digitized  = [to_categorical(target, max_label) for target in y_dev_digitized]\n",
        "y_test_digitized  = [to_categorical(target, max_label) for target in y_test_digitized]\n",
        "y_bios_digitized  = [to_categorical(target, max_label) for target in y_bios_digitized]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7Bm7n5D8lFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_padded = prepro.sequence.pad_sequences(X_digitized, maxlen=MAX_SEQ, padding='post', truncating='post', value=0.0)\n",
        "y_padded = prepro.sequence.pad_sequences(y_digitized, maxlen=MAX_SEQ, padding='post', truncating='post', value=0.0)\n",
        "\n",
        "X_dev_padded = prepro.sequence.pad_sequences(X_dev_digitized, maxlen=MAX_SEQ, padding='post', truncating='post', value=0.0)\n",
        "y_dev_padded = prepro.sequence.pad_sequences(y_dev_digitized, maxlen=MAX_SEQ, padding='post', truncating='post', value=0.0)\n",
        "\n",
        "X_test_padded = prepro.sequence.pad_sequences(X_dev_digitized, maxlen=MAX_SEQ, padding='post', truncating='post', value=0.0)\n",
        "y_test_padded = prepro.sequence.pad_sequences(y_dev_digitized, maxlen=MAX_SEQ, padding='post', truncating='post', value=0.0)\n",
        "\n",
        "X_bios_padded = prepro.sequence.pad_sequences(X_bios_digitized, maxlen=MAX_SEQ, padding='post', truncating='post', value=0.0)\n",
        "y_bios_padded = prepro.sequence.pad_sequences(y_bios_digitized, maxlen=MAX_SEQ, padding='post', truncating='post', value=0.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AETGMnaW8oqf",
        "colab_type": "code",
        "outputId": "8364ddd7-bdb1-46cd-bbb4-683abae815e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "print(X_digitized[0])\n",
        "print(X_padded[0].shape)\n",
        "print(y_padded[0].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 3, 4, 5, 6]\n",
            "(26,)\n",
            "(26, 74)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lRZi_hM8-14",
        "colab_type": "code",
        "outputId": "60ff4f6d-53d3-4b28-f071-8ea372e3e87a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "VOCAB_SIZE = len(vocab)\n",
        "print(MAX_SEQ)\n",
        "CONV_FILTER = [5000,300,500,400,500]\n",
        "CONV_KERNEL = [5,4,3,2,1]\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 5\n",
        "TAG_SIZE = max_label\n",
        "DROP_RATE = .2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6eKVokz9D8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l_inp = Input(shape=(MAX_SEQ,))\n",
        "l_embed = Embedding(VOCAB_SIZE, EMBED_DIM, weights=[embeddings], trainable = True, input_length=MAX_SEQ)(l_inp)\n",
        "\n",
        "\n",
        "l_conv = Conv1D(CONV_FILTER[0], CONV_KERNEL[0], padding='same', activation='relu')(l_embed)\n",
        "l_conv = Conv1D(CONV_FILTER[1], CONV_KERNEL[1], padding='same', activation='relu')(l_conv)\n",
        "# l_conv = Conv1D(CONV_FILTER[2], CONV_KERNEL[2], padding='same', activation='relu')(l_conv)\n",
        "# l_conv = Conv1D(CONV_FILTER[3], CONV_KERNEL[3], padding='same', activation='relu')(l_conv)\n",
        "# l_conv = Conv1D(CONV_FILTER[4], CONV_KERNEL[4], padding='same', activation='relu')(l_conv)\n",
        "\n",
        "l_dense1 = Dense(256, activation='relu')(l_conv)\n",
        "# l_dense2 = Dense(64, activation='relu')(l_dense1)\n",
        "l_output = Dense(TAG_SIZE, activation='softmax')(l_dense1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktQeqQVv9HiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "adam_customized = Adam(lr=0.0004, beta_1=0.85, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTjtMV-H9M7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=l_inp, outputs=l_output)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam_customized, metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb9HoTCi9SGI",
        "colab_type": "code",
        "outputId": "ecfc6d04-63ae-4da5-eb92-a27107080a6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 26)                0         \n",
            "_________________________________________________________________\n",
            "embedding_6 (Embedding)      (None, 26, 300)           10401900  \n",
            "_________________________________________________________________\n",
            "conv1d_14 (Conv1D)           (None, 26, 5000)          7505000   \n",
            "_________________________________________________________________\n",
            "conv1d_15 (Conv1D)           (None, 26, 300)           6000300   \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 26, 256)           77056     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 26, 74)            19018     \n",
            "=================================================================\n",
            "Total params: 24,003,274\n",
            "Trainable params: 24,003,274\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwl5zBXT9XHo",
        "colab_type": "code",
        "outputId": "3bf7b8e6-9da4-413b-abae-4b38bfbb33ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "model.reset_states()\n",
        "r = model.fit(X_padded, y_padded, epochs=EPOCHS, validation_data=(X_dev_padded, y_dev_padded), batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 115812 samples, validate on 15680 samples\n",
            "Epoch 1/5\n",
            "115812/115812 [==============================] - 353s 3ms/step - loss: 0.0918 - acc: 0.6019 - val_loss: 0.0825 - val_acc: 0.6160\n",
            "Epoch 2/5\n",
            "115812/115812 [==============================] - 349s 3ms/step - loss: 0.0460 - acc: 0.6119 - val_loss: 0.0834 - val_acc: 0.6165\n",
            "Epoch 3/5\n",
            "115812/115812 [==============================] - 348s 3ms/step - loss: 0.0282 - acc: 0.6170 - val_loss: 0.0989 - val_acc: 0.6157\n",
            "Epoch 4/5\n",
            "115812/115812 [==============================] - 347s 3ms/step - loss: 0.0164 - acc: 0.6207 - val_loss: 0.1147 - val_acc: 0.6157\n",
            "Epoch 5/5\n",
            "115812/115812 [==============================] - 347s 3ms/step - loss: 0.0105 - acc: 0.6228 - val_loss: 0.1431 - val_acc: 0.6155\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnQXV1-19gTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reshape_predictions(yh, pr):\n",
        "    coords = [np.where(yhh > 0)[0][0] for yhh in yh]\n",
        "    yh = [yhh[co:] for yhh, co in zip(yh, coords)]\n",
        "    ypr = [prr[co:] for prr, co in zip(pr, coords)]\n",
        "    fyh = [c for row in yh for c in row]\n",
        "    fpr = [c for row in ypr for c in row]\n",
        "    return fyh, fpr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw06ZR90up4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "y_pred = model.predict(X_padded).argmax(2)\n",
        "yh = y_padded.argmax(2)\n",
        "fyh, fpr = reshape_predictions(yh, y_pred)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whiAxzv1w4fM",
        "colab_type": "code",
        "outputId": "3f4421c0-72cd-4a43-b8c3-2e4f228ca60b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print('Training accuracy:', accuracy_score(fyh, fpr))\n",
        "# print('Training confusion matrix:')\n",
        "cm = confusion_matrix(fyh, fpr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy: 0.6243464208571451\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENNUxCHhxI_H",
        "colab_type": "code",
        "outputId": "0dad2dc9-5ac9-4330-b8b1-ce7a35d4ebbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(classification_report(fyh, fpr))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00   1125577\n",
            "           1       0.98      0.98      0.98      1853\n",
            "           2       0.97      0.97      0.97      9847\n",
            "           3       0.96      0.99      0.98       695\n",
            "           4       0.99      0.98      0.98       762\n",
            "           5       0.98      0.98      0.98      3237\n",
            "           6       1.00      0.89      0.94         9\n",
            "           7       0.97      0.98      0.98       305\n",
            "           8       1.00      0.92      0.95       954\n",
            "           9       0.99      0.99      0.99      3536\n",
            "          10       1.00      0.97      0.98       417\n",
            "          11       0.71      0.62      0.67         8\n",
            "          12       0.99      0.99      0.99     11897\n",
            "          13       0.98      0.98      0.98      2995\n",
            "          14       1.00      0.99      1.00      9713\n",
            "          15       0.96      0.98      0.97       327\n",
            "          16       0.96      0.99      0.98       799\n",
            "          17       0.98      0.96      0.97      1066\n",
            "          18       0.97      0.98      0.97       855\n",
            "          19       0.98      0.98      0.98      1248\n",
            "          20       0.96      0.95      0.96      8658\n",
            "          21       0.96      0.99      0.97       967\n",
            "          22       0.98      0.98      0.98       814\n",
            "          23       0.97      0.97      0.97      1134\n",
            "          24       1.00      0.86      0.92         7\n",
            "          25       0.94      0.99      0.97       584\n",
            "          26       0.99      0.94      0.97       560\n",
            "          27       0.98      0.99      0.98      4420\n",
            "          28       1.00      0.91      0.95       109\n",
            "          29       1.00      0.10      0.18        10\n",
            "          30       0.98      0.99      0.99     15295\n",
            "          31       0.92      0.99      0.95      1160\n",
            "          32       0.99      0.99      0.99      3903\n",
            "          33       0.95      0.97      0.96       396\n",
            "          34       0.95      0.99      0.97       767\n",
            "          35       0.91      0.97      0.94       859\n",
            "          36       0.97      0.98      0.98      1733\n",
            "          37       0.98      0.99      0.99      1807\n",
            "          38       0.97      0.98      0.98      9490\n",
            "          39       0.97      0.99      0.98       663\n",
            "          40       0.98      0.99      0.98       735\n",
            "          41       0.98      0.99      0.99      3141\n",
            "          42       1.00      0.78      0.88         9\n",
            "          43       0.97      0.99      0.98       284\n",
            "          44       0.98      0.98      0.98       917\n",
            "          45       0.99      1.00      0.99      3348\n",
            "          46       1.00      0.95      0.97       405\n",
            "          47       1.00      0.62      0.77         8\n",
            "          48       0.99      0.99      0.99     11398\n",
            "          49       1.00      1.00      1.00      2870\n",
            "          50       0.99      1.00      1.00      9567\n",
            "          51       0.95      0.95      0.95       312\n",
            "          52       0.96      0.99      0.97       765\n",
            "          53       0.92      0.98      0.95      1047\n",
            "          54       0.98      0.98      0.98       810\n",
            "          55       0.60      1.00      0.75   1685367\n",
            "          56       0.98      0.98      0.98      7643\n",
            "          57       0.97      0.99      0.98      6081\n",
            "          58       0.98      0.98      0.98       133\n",
            "          59       0.99      0.96      0.97       219\n",
            "          60       0.99      0.99      0.99     14779\n",
            "          61       0.95      0.99      0.97       280\n",
            "          62       0.90      1.00      0.95        66\n",
            "          63       0.95      0.99      0.97       775\n",
            "          64       0.99      0.96      0.98       733\n",
            "          65       0.99      0.99      0.99      7401\n",
            "          66       0.95      0.99      0.97      1901\n",
            "          67       0.99      0.99      0.99      8996\n",
            "          68       1.00      0.50      0.67         8\n",
            "          69       1.00      0.98      0.99     10209\n",
            "          70       0.98      0.99      0.99       534\n",
            "          71       0.98      0.92      0.95       215\n",
            "          72       0.95      0.94      0.94       486\n",
            "          73       0.97      0.97      0.97       234\n",
            "\n",
            "    accuracy                           0.62   3011112\n",
            "   macro avg       0.95      0.93      0.93   3011112\n",
            "weighted avg       0.40      0.62      0.48   3011112\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cHoS8QfEcEH",
        "colab_type": "code",
        "outputId": "c9c8c808-5d6f-42ec-bfe2-0c57aa036b3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "y_pred_test = model.predict(X_test_padded).argmax(2)\n",
        "yh_test = y_test_padded.argmax(2)\n",
        "fyh_test, fpr_test = reshape_predictions(yh_test, y_pred_test)\n",
        "print('Training accuracy:', accuracy_score(fyh_test, fpr_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy: 0.6154974489795918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0ueOIVAQhxx",
        "colab_type": "code",
        "outputId": "217db657-4398-4ebc-8eb9-faef2adc01bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(classification_report(fyh_test, fpr_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00    146943\n",
            "           1       0.70      0.66      0.68       312\n",
            "           2       0.82      0.75      0.78      1539\n",
            "           3       0.57      0.54      0.55       113\n",
            "           4       0.53      0.40      0.46        97\n",
            "           5       0.83      0.80      0.82       583\n",
            "           6       0.00      0.00      0.00         1\n",
            "           7       0.71      0.57      0.63        44\n",
            "           8       0.79      0.37      0.50       149\n",
            "           9       0.89      0.89      0.89       521\n",
            "          10       0.83      0.49      0.62        51\n",
            "          11       0.00      0.00      0.00         2\n",
            "          12       0.85      0.81      0.83      1850\n",
            "          13       0.89      0.92      0.91       556\n",
            "          14       0.90      0.85      0.88      1428\n",
            "          15       0.49      0.26      0.34        89\n",
            "          16       0.77      0.69      0.73       141\n",
            "          17       0.67      0.54      0.60       209\n",
            "          18       0.46      0.40      0.42       144\n",
            "          19       0.69      0.68      0.68       194\n",
            "          20       0.81      0.74      0.77      1300\n",
            "          21       0.59      0.49      0.53       142\n",
            "          22       0.63      0.38      0.47       114\n",
            "          23       0.76      0.72      0.74       178\n",
            "          25       0.59      0.60      0.60        95\n",
            "          26       0.66      0.39      0.49        75\n",
            "          27       0.90      0.92      0.91       641\n",
            "          28       0.40      0.14      0.21        14\n",
            "          29       0.00      0.00      0.00         2\n",
            "          30       0.83      0.84      0.84      2373\n",
            "          31       0.77      0.88      0.82       216\n",
            "          32       0.83      0.81      0.82       451\n",
            "          33       0.79      0.44      0.57       123\n",
            "          34       0.69      0.79      0.74       136\n",
            "          35       0.60      0.57      0.59       139\n",
            "          36       0.37      0.43      0.40       250\n",
            "          37       0.72      0.72      0.72       304\n",
            "          38       0.84      0.80      0.82      1487\n",
            "          39       0.65      0.49      0.56       108\n",
            "          40       0.58      0.51      0.54        97\n",
            "          41       0.85      0.86      0.86       566\n",
            "          42       0.00      0.00      0.00         1\n",
            "          43       0.58      0.51      0.54        43\n",
            "          44       0.73      0.60      0.66       144\n",
            "          45       0.94      0.97      0.95       494\n",
            "          46       0.79      0.45      0.58        51\n",
            "          47       0.00      0.00      0.00         2\n",
            "          48       0.87      0.81      0.84      1778\n",
            "          49       0.97      0.97      0.97       543\n",
            "          50       0.88      0.84      0.86      1403\n",
            "          51       0.50      0.14      0.22        87\n",
            "          52       0.82      0.82      0.82       136\n",
            "          53       0.68      0.72      0.70       202\n",
            "          54       0.43      0.29      0.34       139\n",
            "          55       0.60      0.99      0.75    229300\n",
            "          56       0.72      0.69      0.70      1199\n",
            "          57       0.83      0.80      0.81      1177\n",
            "          58       0.86      0.15      0.26        39\n",
            "          59       0.36      0.22      0.27        23\n",
            "          60       0.90      0.87      0.88      2451\n",
            "          61       0.62      0.58      0.60        31\n",
            "          62       0.27      0.75      0.40         4\n",
            "          63       0.67      0.56      0.61       113\n",
            "          64       0.90      0.75      0.82       141\n",
            "          65       0.88      0.82      0.85      1034\n",
            "          66       0.69      0.74      0.71       295\n",
            "          67       0.87      0.72      0.79      1431\n",
            "          68       0.00      0.00      0.00         1\n",
            "          69       0.93      0.72      0.81      1395\n",
            "          70       0.54      0.25      0.34        84\n",
            "          71       0.12      0.05      0.07        21\n",
            "          72       0.67      0.49      0.56       107\n",
            "          73       0.53      0.24      0.33        34\n",
            "\n",
            "    accuracy                           0.62    407680\n",
            "   macro avg       0.64      0.56      0.58    407680\n",
            "weighted avg       0.40      0.62      0.48    407680\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtSAgN5qW0Of",
        "colab_type": "code",
        "outputId": "5b5bb638-c780-45ce-a6f0-f9beb8923030",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "y_pred_bios = model.predict(X_bios_padded).argmax(2)\n",
        "yh_bios = y_bios_padded.argmax(2)\n",
        "fyh_bios, fpr_bios = reshape_predictions(yh_bios, y_pred_bios)\n",
        "print('Training accuracy:', accuracy_score(fyh_bios, fpr_bios))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy: 0.5680682312038244\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JJCN4HwEG5v",
        "colab_type": "code",
        "outputId": "9c79fe3d-c6f6-4298-95a8-bf3b95a3ba3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "print('Training confusion matrix:')\n",
        "print(confusion_matrix(fyh_bios, fpr_bios))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training confusion matrix:\n",
            "[[  0   0   0 ...   0   0   0]\n",
            " [  0 125   0 ...   0   0   0]\n",
            " [  0   0   0 ...   0   0   0]\n",
            " ...\n",
            " [  0   0   0 ... 188   0   0]\n",
            " [  0   0   0 ...   2   0   0]\n",
            " [  0   0   0 ...   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaBtOc7NS8CB",
        "colab_type": "code",
        "outputId": "c651346a-0d68-480c-f1a6-1bdcdf6c40d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "y_bios_flat = chain.from_iterable(data.y.tolist())\n",
        "\n",
        "\n",
        "counts = Counter(y_bios_flat)\n",
        "\n",
        "print(counts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'O': 10059, 'I-ORG': 1278, 'B-ORG': 886, 'L-ORG': 886, 'U-TITLE': 498, 'B-DATE': 340, 'L-DATE': 340, 'B-TITLE': 311, 'L-TITLE': 311, 'I-DATE': 309, 'I-TITLE': 275, 'U-PERSON': 252, 'U-ORG': 239, 'U-DATE': 227, 'B-PERSON': 102, 'L-PERSON': 102, 'I-PERSON': 77, 'U-GPE': 47, 'I-PRODUCT': 27, 'U-PRODUCT': 27, 'B-GPE': 22, 'L-GPE': 22, 'B-PRODUCT': 17, 'L-PRODUCT': 17, 'I-GPE': 7, 'U-NORP': 4, 'B-MONEY': 3, 'L-MONEY': 3, 'B-LAW': 3, 'L-LAW': 3, 'B-PERCENT': 2, 'L-PERCENT': 2, 'U-CARDINAL': 2, 'I-LAW': 2, 'B-NORP': 2, 'L-NORP': 2, 'U-ORDINAL': 2, 'U-LOC': 2, 'I-MONEY': 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFehPBRHf6iU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OrderedDict(counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai-YPqI0MmdA",
        "colab_type": "code",
        "outputId": "38776b99-d0e8-445f-f5f3-eb9a8a8e6e79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(classification_report(fyh_bios, fpr_bios))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      5817\n",
            "           2       0.76      0.51      0.61       246\n",
            "           3       0.00      0.00      0.00         0\n",
            "           5       0.50      0.12      0.19        17\n",
            "           7       0.50      0.33      0.40         3\n",
            "           8       0.00      0.00      0.00         0\n",
            "           9       1.00      1.00      1.00         1\n",
            "          10       0.00      0.00      0.00         2\n",
            "          12       0.72      0.61      0.66       699\n",
            "          13       0.00      0.00      0.00         1\n",
            "          14       0.84      0.81      0.83        97\n",
            "          15       0.00      0.00      0.00        15\n",
            "          18       0.00      0.00      0.00         0\n",
            "          20       0.63      0.42      0.51       177\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.50      0.40      0.44         5\n",
            "          25       0.06      0.50      0.11         2\n",
            "          26       0.00      0.00      0.00         0\n",
            "          27       1.00      1.00      1.00         1\n",
            "          30       0.58      0.73      0.65       932\n",
            "          31       0.00      0.00      0.00         0\n",
            "          32       0.72      0.84      0.77        74\n",
            "          33       0.00      0.00      0.00        25\n",
            "          36       0.00      0.00      0.00         0\n",
            "          38       0.90      0.58      0.70       229\n",
            "          39       0.00      0.00      0.00         0\n",
            "          40       0.00      0.00      0.00         0\n",
            "          41       0.80      0.25      0.38        16\n",
            "          43       0.33      0.67      0.44         3\n",
            "          44       0.00      0.00      0.00         0\n",
            "          45       1.00      1.00      1.00         1\n",
            "          46       0.00      0.00      0.00         2\n",
            "          48       0.75      0.61      0.67       666\n",
            "          49       1.00      1.00      1.00         1\n",
            "          50       0.77      0.69      0.73        97\n",
            "          51       0.00      0.00      0.00        15\n",
            "          54       0.00      0.00      0.00         0\n",
            "          55       0.54      0.93      0.69      8591\n",
            "          56       0.04      1.00      0.08         1\n",
            "          57       0.59      0.69      0.64       190\n",
            "          60       0.39      0.52      0.45        29\n",
            "          63       0.00      0.00      0.00         2\n",
            "          65       0.33      1.00      0.50         1\n",
            "          66       0.67      1.00      0.80         2\n",
            "          67       0.80      0.27      0.40       183\n",
            "          69       0.96      0.79      0.87       238\n",
            "          70       0.00      0.00      0.00        27\n",
            "          73       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.57     18408\n",
            "   macro avg       0.37      0.38      0.34     18408\n",
            "weighted avg       0.41      0.57      0.46     18408\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG2O6B08qKx4",
        "colab_type": "code",
        "outputId": "3a655a06-3c6b-4392-ba3c-bd00c57e0fa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "score = model.evaluate(X_bios_padded, y_bios_padded)\n",
        "print(f'Model loss: {score}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "708/708 [==============================] - 1s 822us/step\n",
            "Model loss: [0.8057204478204587, 0.5680682335869741]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y37-ZOHLwVy9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeCEyhlZxxRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM04EROCyHM3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}