{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w266-project-c-rnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IidDeSPASwk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install gensim\n",
        "# !pip install tf-nightly-2.0-preview\n",
        "# !pip install plotly-express\n",
        "\n",
        "\n",
        "# !pip uninstall tensorflow==tf-nightly-2.0-preview\n",
        "\n",
        "# !pip install tensorflow\n",
        "# !pip uninstall tensor-hub==0.5.0\n",
        "\n",
        "\n",
        "# !pip install tensorflow-hub==0.4.0\n",
        "# !pip install tensorflow==1.9.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92IsOYzajEfB",
        "colab_type": "code",
        "outputId": "e6c4bdea-833e-4621-e140-f9b872816a76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import gzip\n",
        "drive.mount('/content/drive/')\n",
        "__dir__ = '/content/drive/My Drive/W266_Project'\n",
        "\n",
        "GZIP_FILE = __dir__ + '/data/GoogleNews-vectors-negative300.bin.gz'\n",
        "# f = gzip.open(GZIP_FILE, 'r')\n",
        "# DATA_FILE = __dir__ + 'data/GoogleNews-vectors-negative300.txt'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbRct2Q6SN9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBED_DIM = 300\n",
        "MAX_SEQ = 26\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-2HlSC6UmJm",
        "colab_type": "code",
        "outputId": "10586840-8c8b-464c-988e-ac3d98b4238d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "# import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import gensim\n",
        "import re, os, csv\n",
        "from smart_open import open\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from collections import Counter, defaultdict\n",
        "import pandas as pd\n",
        "from itertools import chain\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support,classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from keras import preprocessing as prepro\n",
        "from keras.layers import TimeDistributed, Dense, Activation, Input, Conv1D, Embedding, GlobalMaxPooling1D, Dropout\n",
        "from keras.layers import concatenate, SimpleRNN, LSTM, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import Adam\n",
        "from keras import metrics\n",
        "\n",
        "from tensorflow.python.tools import inspect_checkpoint as chkp\n",
        "%matplotlib inline\n",
        "print(tf.__version__)\n",
        "# print(hub.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLq4xOzKU2Yw",
        "colab_type": "code",
        "outputId": "016cba88-b5c2-4d66-9587-e4261c27297b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "print('This may take a few minutes..')\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format(GZIP_FILE, binary=True)\n",
        "# model.save(word_embeddings)\n",
        "# model.save_word2vec_format(DATA_FILE, binary=False)\n",
        "print('Done!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This may take a few minutes..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSH7_Vc3xrHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def checkPrior(blah):\n",
        "\tif (blah.prior is None or blah.prior is np.NaN) and (blah.prior_pos is None or blah.prior_pos is np.NaN):\n",
        "\t\treturn True\n",
        "\telse:\n",
        "\t\treturn False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGGwNLxOrBPY",
        "colab_type": "code",
        "outputId": "611f5b34-01d2-406f-c0f3-bf2ab5046434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "def create_onto_data_vectors(data_type):\n",
        "  data_type_dict = {'test' : '/content/drive/My Drive/W266_Project/data/onto.test.ner',\n",
        "                   'dev' : '/content/drive/My Drive/W266_Project/data/onto.development.ner',\n",
        "                   'train' : '/content/drive/My Drive/W266_Project/data/onto.train.ner'}\n",
        "  header = 0\n",
        "  if 'onto' in data_type_dict[data_type]:\n",
        "    header = None\n",
        "  data = pd.read_csv(data_type_dict[data_type], sep=\"\\t\",  quoting=csv.QUOTE_NONE, header=header, skip_blank_lines=False, engine='python', names =['token', 'pos', 'tree', 'label'])\n",
        "\n",
        "  # see if prior row was a newline\n",
        "  data['prior'] = data.token.shift(1)\n",
        "  data['prior_pos'] = data.pos.shift(1)\n",
        "  # drop empty rows\n",
        "  data = data.loc[~data.token.isnull()]\n",
        "  data.prior = data.apply(checkPrior, axis=1)\n",
        "  data['phrase'] = data.prior.cumsum()\n",
        "  df = data.groupby('phrase').agg({'token':list, 'label': list})\n",
        "  X = df['token'].tolist()\n",
        "  y = df['label'].tolist()\n",
        "  return X, y\n",
        "\n",
        "X, y = create_onto_data_vectors('train')\n",
        "\n",
        "X_dev, y_dev = create_onto_data_vectors('dev')\n",
        "\n",
        "X_test, y_test = create_onto_data_vectors('test')\n",
        "\n",
        "print(len(X))\n",
        "print(len(y))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "115812\n",
            "115812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFpe_Ln0q85F",
        "colab_type": "code",
        "outputId": "4935d2d5-9198-4ca6-c97f-a5c6d49d4410",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# X, y = numpy.array(X), numpy.array(y)\n",
        "# # print(X[1])\n",
        "# # print(y[1])\n",
        "# data_len = [len(x) for x in X]\n",
        "# print(sum(data_len)/len(X))\n",
        "# fig = plotly.graph_objects.FigureWidget(data = plotly.graph_objects.Bar(data_len))\n",
        "# fig.show()\n",
        "\n",
        "def filter_data_seq(X):\n",
        "  max_length = MAX_SEQ\n",
        "  lengths = [len(x) for x in X]\n",
        "  print(f'Maximum length: {max(lengths)}')\n",
        "  print(f'Minimum length: {min(lengths)}')\n",
        "  print(f'Average length: {sum(lengths)/len(lengths)}')\n",
        "  \n",
        "  short_sentences = [s for s in X if len(s) <= max_length]\n",
        "  print(f'% of short sentences - {100 * len(short_sentences)/len(lengths)}%')\n",
        "\n",
        "filter_data_seq(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum length: 228\n",
            "Minimum length: 1\n",
            "Average length: 19.003652471246504\n",
            "% of short sentences - 76.4808482713363%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZuTXpy13oi3",
        "colab_type": "code",
        "outputId": "bf9dcba2-69ae-4415-e201-b5c7921b926c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "corpus = [token for sentence in X for token in sentence]\n",
        "vocab = ['<PAD>', '<UNK>'] + [token for token, count in Counter(corpus).items() if count >= 2]\n",
        "print(f'Length of vocabulary - {len(vocab)}')\n",
        "token2index = defaultdict(lambda: 1, {token: index for index, token in  enumerate(vocab)})\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of vocabulary - 34670\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk4Wq16HyYfk",
        "colab_type": "code",
        "outputId": "a7f3a514-74f9-4966-e2cf-b31a4e88bb8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embeddings = np.zeros((len(token2index.keys()), EMBED_DIM))\n",
        "no_embed = []\n",
        "print(embeddings.shape)\n",
        "\n",
        "for k, v in token2index.items():\n",
        "   try:\n",
        "      embeddings[v] = model[k]\n",
        "   except:\n",
        "      no_embed.append((k,v))\n",
        "      continue"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(34670, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xjYF09dgetw",
        "colab_type": "code",
        "outputId": "bb854c7b-97b8-4f20-a9ca-d4e68bf5fc7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# print(embeddings[2])\n",
        "print(f'% of volcabulary with no embeddings - {100 * len(no_embed)/len(vocab)}%')\n",
        "\n",
        "# print(model['of'])\n",
        "# print(embeddings[4])\n",
        "# np,random.randn(.25)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of volcabulary with no embeddings - 8.269397173348716%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB9amLUZL4MH",
        "colab_type": "code",
        "outputId": "e65d1c2b-2cff-4dfb-910d-68ee9ae68c5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# df_vocab = pd.DataFrame(list(token2index.items()), columns=['token', 'indx'])\n",
        "\n",
        "\n",
        "\n",
        "label_vocab = ['<PAD>'] + list(set([label for target_list in y for label in target_list]))\n",
        "\n",
        "label2index = {label : index for index, label in enumerate(label_vocab)}\n",
        "\n",
        "print(f'Length of labels - {len(label2index)}')\n",
        "\n",
        "max_label = len(label2index)\n",
        "# print(label2index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of labels - 38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Kl7C2_YUoHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FILE_PATH = '/content/drive/My Drive/W266_Project/data/bios-tagged-final-flat.csv'\n",
        "\n",
        "header = 0\n",
        "if 'onto' in FILE_PATH:\n",
        "\theader = None\n",
        "data = pd.read_csv(FILE_PATH, sep=\"\\t\",  quoting=csv.QUOTE_NONE, header=header, skip_blank_lines=False, engine='python', names =['token', 'pos', 'tree', 'label'])\n",
        "\n",
        "# see if prior row was a newline\n",
        "data['prior'] = data.token.shift(1)\n",
        "data['prior_pos'] = data.pos.shift(1)\n",
        "# drop empty rows\n",
        "data = data.loc[~data.token.isnull()]\n",
        "data.prior = data.apply(checkPrior, axis=1)\n",
        "data['phrase'] = data.prior.cumsum()\n",
        "\n",
        "#aggregate by sentence\n",
        "bios_df = data.groupby('phrase').agg({'token':list, 'label': list})\n",
        "X_bios = bios_df['token'].tolist()\n",
        "y_bios = bios_df['label'].tolist()\n",
        "\n",
        "y_bios_no_title = [['O' if label in ['B-TITLE','U-TITLE','L-TITLE','I-TITLE'] else label for label in seq] for seq in y_bios]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKhrWuCQCSdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_digitized = [[token2index[word] for word in seq] for seq in X] \n",
        "y_digitized = [[label2index[label] for label in seq] for seq in y]\n",
        "\n",
        "X_dev_digitized = [[token2index[word] for word in seq] for seq in X_dev] \n",
        "y_dev_digitized = [[label2index[label] for label in seq] for seq in y_dev] \n",
        "\n",
        "X_test_digitized = [[token2index[word] for word in seq] for seq in X_test] \n",
        "y_test_digitized = [[label2index[label] for label in seq] for seq in y_test] \n",
        "\n",
        "X_bios_digitized = [[token2index[word] for word in seq] for seq in X_bios] \n",
        "y_bios_digitized = [[label2index[label] for label in seq] for seq in y_bios_no_title] \n",
        "\n",
        "\n",
        "\n",
        "y_digitized  = [to_categorical(target, max_label) for target in y_digitized]\n",
        "y_dev_digitized  = [to_categorical(target, max_label) for target in y_dev_digitized]\n",
        "y_test_digitized  = [to_categorical(target, max_label) for target in y_test_digitized]\n",
        "y_bios_digitized  = [to_categorical(target, max_label) for target in y_bios_digitized]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ppr1br1p0Sj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_padded = prepro.sequence.pad_sequences(X_digitized, maxlen=MAX_SEQ, padding='post', truncating='post', value=0.0)\n",
        "y_padded = prepro.sequence.pad_sequences(y_digitized, maxlen=MAX_SEQ, padding='post', truncating='post', value=0.0)\n",
        "\n",
        "X_dev_padded = prepro.sequence.pad_sequences(X_dev_digitized, maxlen=MAX_SEQ, padding='post', truncating='post', value=0.0)\n",
        "y_dev_padded = prepro.sequence.pad_sequences(y_dev_digitized, maxlen=MAX_SEQ, padding='post', truncating='post', value=0.0)\n",
        "\n",
        "X_test_padded = prepro.sequence.pad_sequences(X_test_digitized, maxlen=MAX_SEQ, padding='post', truncating='post', value=0.0)\n",
        "y_test_padded = prepro.sequence.pad_sequences(y_test_digitized, maxlen=MAX_SEQ, padding='post', truncating='post', value=0.0)\n",
        "\n",
        "X_bios_padded = prepro.sequence.pad_sequences(X_bios_digitized, maxlen=MAX_SEQ, padding='post', truncating='post', value=0.0)\n",
        "y_bios_padded = prepro.sequence.pad_sequences(y_bios_digitized, maxlen=MAX_SEQ, padding='post', truncating='post', value=0.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUU7KnjToh20",
        "colab_type": "code",
        "outputId": "42114037-954d-45b8-a55c-906af0aa3fb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(X_digitized[0])\n",
        "print(X_padded[0].shape)\n",
        "print(y_padded[0].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 3, 4, 5, 6]\n",
            "(26,)\n",
            "(26, 38)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tU3CmL69PrR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x_model = tf.placeholder(tf.int32, shape=[None, MAX_SEQ])\n",
        "# with tf.device(\"/cpu:0\"):\n",
        "#   embedded_x = tf.nn.embedding_lookup(embeddings, x_model)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7xZ1URR9q03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzUfVUH6IZ7G",
        "colab_type": "code",
        "outputId": "87083dd2-8ef1-465e-c88a-2c4d74beda80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "VOCAB_SIZE = len(vocab)\n",
        "print(MAX_SEQ)\n",
        "CONV_FILTER = [5000,300,500,400,500]\n",
        "CONV_KERNEL = [5,4,3,2,1]\n",
        "BATCH_SIZE = 400\n",
        "EPOCHS = 5\n",
        "TAG_SIZE = max_label\n",
        "DROP_RATE = .2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw6PERmQz5MX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmyPidMCAaOr",
        "colab_type": "code",
        "outputId": "13cb355a-9537-4ad3-f3d1-11b2fd0bdbdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "l_inp = Input(shape=(MAX_SEQ,))\n",
        "l_embed = Embedding(VOCAB_SIZE, EMBED_DIM, weights=[embeddings], trainable = True, input_length=MAX_SEQ)(l_inp)\n",
        "\n",
        "\n",
        "l_conv = Conv1D(CONV_FILTER[0], CONV_KERNEL[0], padding='same', activation='relu')(l_embed)\n",
        "l_conv = Conv1D(CONV_FILTER[1], CONV_KERNEL[1], padding='same', activation='relu')(l_conv)\n",
        "# l_conv = Conv1D(CONV_FILTER[2], CONV_KERNEL[2], padding='same', activation='relu')(l_conv)\n",
        "# l_conv = Conv1D(CONV_FILTER[3], CONV_KERNEL[3], padding='same', activation='relu')(l_conv)\n",
        "# l_conv = Conv1D(CONV_FILTER[4], CONV_KERNEL[4], padding='same', activation='relu')(l_conv)\n",
        "\n",
        "l_dense1 = Dense(256, activation='relu')(l_conv)\n",
        "# l_dense2 = Dense(64, activation='relu')(l_dense1)\n",
        "l_output = Dense(TAG_SIZE, activation='softmax')(l_dense1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0803 20:25:37.798830 139645022852992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0803 20:25:37.863134 139645022852992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0803 20:25:37.875210 139645022852992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0803 20:25:37.895916 139645022852992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0803 20:25:37.897227 139645022852992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzpM05F310XA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "adam_customized = Adam(lr=0.0004, beta_1=0.85, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srAokiZYE1ev",
        "colab_type": "code",
        "outputId": "576ee44e-787f-4949-e9bf-10c6d1b338a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "model = Model(inputs=l_inp, outputs=l_output)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam_customized, metrics=['acc'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0803 20:25:45.350965 139645022852992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSPbSamnYbnr",
        "colab_type": "code",
        "outputId": "9467a18a-358b-451d-eec5-5a4de8ec6166",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 26)                0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 26, 300)           10401000  \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 26, 5000)          7505000   \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 26, 300)           6000300   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 26, 256)           77056     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 26, 38)            9766      \n",
            "=================================================================\n",
            "Total params: 23,993,122\n",
            "Trainable params: 23,993,122\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VYMakvRbE_W",
        "colab_type": "code",
        "outputId": "48a40068-dcc7-4480-8cc0-3a0e3471faef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "model.reset_states()\n",
        "r = model.fit(X_padded, y_padded, epochs=EPOCHS, validation_data=(X_dev_padded, y_dev_padded), batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 115812 samples, validate on 15680 samples\n",
            "Epoch 1/5\n",
            "115812/115812 [==============================] - 148s 1ms/step - loss: 0.0801 - acc: 0.6029 - val_loss: 0.0867 - val_acc: 0.6140\n",
            "Epoch 2/5\n",
            "115812/115812 [==============================] - 141s 1ms/step - loss: 0.0565 - acc: 0.6088 - val_loss: 0.0801 - val_acc: 0.6157\n",
            "Epoch 3/5\n",
            "115812/115812 [==============================] - 141s 1ms/step - loss: 0.0436 - acc: 0.6125 - val_loss: 0.0818 - val_acc: 0.6157\n",
            "Epoch 4/5\n",
            "115812/115812 [==============================] - 141s 1ms/step - loss: 0.0338 - acc: 0.6155 - val_loss: 0.0851 - val_acc: 0.6163\n",
            "Epoch 5/5\n",
            "115812/115812 [==============================] - 141s 1ms/step - loss: 0.0257 - acc: 0.6180 - val_loss: 0.0909 - val_acc: 0.6163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaCDkauwJY_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(__dir__+'/Model_Output/cnn_bio_architecture.json', 'w') as f:\n",
        "    f.write(model.to_json())\n",
        "\n",
        "model.save_weights(__dir__+'/Model_Output/cnn_bio_model_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwkk5bHtfjWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reshape_predictions(yh, pr):\n",
        "    coords = [np.where(yhh > 0)[0][0] for yhh in yh]\n",
        "    yh = [yhh[co:] for yhh, co in zip(yh, coords)]\n",
        "    ypr = [prr[co:] for prr, co in zip(pr, coords)]\n",
        "    fyh = [c for row in yh for c in row]\n",
        "    fpr = [c for row in ypr for c in row]\n",
        "    return fyh, fpr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2qBp4XF13N3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "y_pred = model.predict(X_padded).argmax(2)\n",
        "yh = y_padded.argmax(2)\n",
        "fyh, fpr = reshape_predictions(yh, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6nE8H4tcR-k",
        "colab_type": "code",
        "outputId": "153886a5-6b34-499c-9dff-d91c28b5f32f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print('Training accuracy:', accuracy_score(fyh, fpr))\n",
        "# print('Training confusion matrix:')\n",
        "cm = confusion_matrix(fyh, fpr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy: 0.6244500370627197\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypQ1e9R-R1_r",
        "colab_type": "code",
        "outputId": "c73b25c5-ad5f-458a-f874-47f57fb83e3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        }
      },
      "source": [
        "print(classification_report(fyh, fpr))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00   1125578\n",
            "           1       0.98      0.98      0.98      1014\n",
            "           2       0.98      0.95      0.97      1549\n",
            "           3       1.00      0.94      0.97        16\n",
            "           4       0.99      0.99      0.99     19922\n",
            "           5       0.97      0.98      0.97      1477\n",
            "           6       0.90      0.98      0.94      1906\n",
            "           7       0.99      0.63      0.77       708\n",
            "           8       0.98      0.97      0.97       289\n",
            "           9       0.96      0.99      0.97     18148\n",
            "          10       0.99      0.99      0.99     20890\n",
            "          11       0.98      0.98      0.98       828\n",
            "          12       0.99      0.99      0.99      4030\n",
            "          13       0.99      0.99      0.99     26693\n",
            "          14       0.99      0.99      0.99      7818\n",
            "          15       0.98      0.99      0.98      3055\n",
            "          16       0.97      0.99      0.98       514\n",
            "          17       0.99      0.97      0.98       981\n",
            "          18       0.92      0.97      0.94      1089\n",
            "          19       0.98      0.98      0.98      1729\n",
            "          20       0.97      1.00      0.98     13466\n",
            "          21       0.98      1.00      0.99      3003\n",
            "          22       0.95      0.99      0.97     15928\n",
            "          23       0.96      0.95      0.95      1552\n",
            "          24       0.82      0.78      0.80        18\n",
            "          25       0.98      0.97      0.97      1909\n",
            "          26       0.99      0.99      0.99     18016\n",
            "          27       0.87      0.98      0.92       868\n",
            "          28       0.82      0.99      0.90      2543\n",
            "          29       0.98      0.98      0.98      4269\n",
            "          30       0.96      0.96      0.96       371\n",
            "          31       0.98      0.89      0.93       861\n",
            "          32       0.97      0.98      0.98      1630\n",
            "          33       0.98      1.00      0.99      7768\n",
            "          34       0.99      0.98      0.98      1532\n",
            "          35       0.60      1.00      0.75   1685373\n",
            "          36       0.98      0.99      0.98      4275\n",
            "          37       0.93      0.99      0.96      9496\n",
            "\n",
            "    accuracy                           0.62   3011112\n",
            "   macro avg       0.93      0.94      0.93   3011112\n",
            "weighted avg       0.40      0.62      0.48   3011112\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOOGFqeXyB9l",
        "colab_type": "code",
        "outputId": "f81ddbe5-0da2-4a94-90b7-3be971182c40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "y_pred_test = model.predict(X_test_padded).argmax(2)\n",
        "yh_test = y_test_padded.argmax(2)\n",
        "fyh_test, fpr_test = reshape_predictions(yh_test, y_pred_test)\n",
        "print('Training accuracy:', accuracy_score(fyh_test, fpr_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy: 0.5955446697854818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1vkT3Vczf1E",
        "colab_type": "code",
        "outputId": "fb3ac1e5-39fe-4069-fbe4-04393d9e22a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        }
      },
      "source": [
        "print(classification_report(fyh_test, fpr_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00    121404\n",
            "           1       0.71      0.55      0.62       128\n",
            "           2       0.68      0.44      0.53       178\n",
            "           4       0.87      0.80      0.83      1939\n",
            "           5       0.67      0.64      0.65       158\n",
            "           6       0.54      0.55      0.55       235\n",
            "           7       0.76      0.25      0.38        51\n",
            "           8       0.75      0.32      0.44        19\n",
            "           9       0.79      0.80      0.80      1833\n",
            "          10       0.81      0.76      0.79      1692\n",
            "          11       0.67      0.56      0.61        75\n",
            "          12       0.91      0.90      0.90       455\n",
            "          13       0.81      0.82      0.81      2196\n",
            "          14       0.84      0.80      0.82       819\n",
            "          15       0.77      0.67      0.71       318\n",
            "          16       0.80      0.42      0.55       143\n",
            "          17       0.59      0.28      0.38       121\n",
            "          18       0.55      0.49      0.51       144\n",
            "          19       0.67      0.63      0.65       172\n",
            "          20       0.83      0.86      0.84      1337\n",
            "          21       0.84      0.90      0.87       314\n",
            "          22       0.73      0.82      0.77      1536\n",
            "          23       0.56      0.44      0.49       213\n",
            "          24       0.00      0.00      0.00         6\n",
            "          25       0.61      0.60      0.61       184\n",
            "          26       0.84      0.84      0.84      2096\n",
            "          27       0.42      0.37      0.39        86\n",
            "          28       0.34      0.43      0.38       269\n",
            "          29       0.79      0.78      0.79       279\n",
            "          30       0.58      0.44      0.50        32\n",
            "          31       0.77      0.39      0.51        70\n",
            "          32       0.57      0.63      0.60       133\n",
            "          33       0.88      0.90      0.89       545\n",
            "          34       0.76      0.76      0.76       214\n",
            "          35       0.58      0.99      0.73    176762\n",
            "          36       0.85      0.77      0.81       593\n",
            "          37       0.64      0.71      0.67       893\n",
            "\n",
            "    accuracy                           0.60    317642\n",
            "   macro avg       0.67      0.60      0.62    317642\n",
            "weighted avg       0.37      0.60      0.46    317642\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VNrbwe2sfCD",
        "colab_type": "code",
        "outputId": "d400172f-83e5-455d-839f-89cdbea6072e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "y_pred_bios = model.predict(X_bios_padded).argmax(2)\n",
        "yh_bios = y_bios_padded.argmax(2)\n",
        "fyh_bios, fpr_bios = reshape_predictions(yh_bios, y_pred_bios)\n",
        "print('Training accuracy:', accuracy_score(fyh_bios, fpr_bios))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy: 0.5757279443720121\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvk4McokuTsy",
        "colab_type": "code",
        "outputId": "e3f12852-ec48-484e-eab4-87af0b4175bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "print(classification_report(fyh_bios, fpr_bios))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      5818\n",
            "           2       0.00      0.00      0.00         0\n",
            "           4       0.91      0.80      0.86       335\n",
            "           5       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00        40\n",
            "           9       0.81      0.56      0.66       406\n",
            "          10       0.69      0.55      0.61       882\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.50      1.00      0.67         1\n",
            "          13       0.72      0.69      0.71      1597\n",
            "          14       0.14      0.33      0.20         3\n",
            "          16       1.00      0.50      0.67         2\n",
            "          18       0.00      0.00      0.00         0\n",
            "          19       0.00      0.00      0.00         2\n",
            "          20       0.68      0.85      0.76       171\n",
            "          21       0.00      0.00      0.00         1\n",
            "          22       0.78      0.71      0.74       436\n",
            "          25       0.67      1.00      0.80         2\n",
            "          26       0.38      0.35      0.36        46\n",
            "          27       0.40      0.80      0.53         5\n",
            "          28       0.00      0.00      0.00         0\n",
            "          29       1.00      1.00      1.00         1\n",
            "          30       0.50      0.33      0.40         3\n",
            "          31       0.00      0.00      0.00        42\n",
            "          32       0.00      0.00      0.00         0\n",
            "          33       1.00      1.00      1.00         2\n",
            "          35       0.54      0.93      0.69      8591\n",
            "          36       0.55      0.29      0.37        21\n",
            "          37       0.02      1.00      0.04         1\n",
            "\n",
            "    accuracy                           0.58     18408\n",
            "   macro avg       0.39      0.44      0.38     18408\n",
            "weighted avg       0.41      0.58      0.47     18408\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9VtDS0vWRWY",
        "colab_type": "code",
        "outputId": "22b032dd-c7f3-446c-b891-b8846f0df63e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "score = model.evaluate(X_bios_padded, y_bios_padded)\n",
        "print(f'Model loss: {score}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "708/708 [==============================] - 1s 796us/step\n",
            "Model loss: [0.614660323339667, 0.5757279448253286]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGMMM0xIsduE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KM-8_KzpvCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Th5XbkNypyNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}